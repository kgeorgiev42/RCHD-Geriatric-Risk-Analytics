{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e24eb42-b904-4046-8aad-7bd98a8d2a66",
   "metadata": {},
   "source": [
    "#### Generate features for ML predictions of adverse outcomes and in-hospital rehabilitation needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1e471-6fb6-4a35-af91-b879bbc91902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.dates import DateFormatter\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56858068-1e11-44b7-92a5-f94acd2fb15d",
   "metadata": {},
   "source": [
    "##### Load routine data and cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa4427-8be3-4d2c-867e-17fe17e420a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data = pd.read_csv('')\n",
    "print(inp_data.shape, inp_data.ppid.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f380be5a-8a71-4657-8e67-5f5cebdbf02c",
   "metadata": {},
   "source": [
    "##### Set 65+ cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9946a-4770-40ef-a668-202050d8c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(inp_data[inp_data.total_count_all>0]) / len(inp_data))\n",
    "print(len(inp_data[inp_data.total_count_rehab>0]) / len(inp_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92681f16-c9f3-4473-9193-6af81565266e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30864f8-8655-4114-ba5a-626a4fbff80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comorbidities\n",
    "smr_data = pd.read_csv('', sep='\\t', low_memory=False, encoding='iso-8859-1')\n",
    "gp_data = pd.read_csv('', sep='\\t', low_memory=False, encoding='iso-8859-1')\n",
    "## TRAK Questionnaires\n",
    "trq_4at = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "trq_BBF = pd.read_csv('', sep='\\t', low_memory=False, encoding='iso-8859-1')\n",
    "trq_falls = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "trq_mobility = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "trq_MRSA = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "trq_MUST = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "trq_nutr = pd.read_csv('', sep='\\t', low_memory=False, encoding='iso-8859-1')\n",
    "trq_RUB = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "trq_wt = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "## ICU/HDU data\n",
    "ww_hai = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "ww_howie = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "ww_ph = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "ww_sics = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "ww_adm = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "## Demographics\n",
    "demo_data = pd.read_csv('', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50d3fb-b594-402d-83ba-42ec35aee084",
   "metadata": {},
   "source": [
    "##### Select features in inpatient cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14c3cb7-7277-48e7-a895-c858e57c7840",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad86b4-022f-435a-9cc7-5965085a4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_data.isnull().sum().tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb637dff-2a3d-4c5f-85f9-768b83f53c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = inp_data[['ppid', 'EpisodeNumber', 'AdmissionDate', 'ED_adate_dt', 'IndexAttDate', 'HOSP_adt', 'DischargeDate', 'HOSP_ddt',\n",
    "                   'breq_dt', 'HOSP_FCC_dt', 'HOSP_FAS_dt',\n",
    "                   'AgeAtAdmission', 'Sex', 'simd_dec', 'PresentingCondition', 'AttendedED',\n",
    "                   'arrival_mode', 'triage_code',\n",
    "                   'gt_m', 'gt_cc', 'gt_es_hosp', 'gt_dd',\n",
    "                  'total_count_all', 'total_count_rehab']]\n",
    "print(inp_ch.shape)\n",
    "### Get only valid ED dates\n",
    "inp_ch = inp_ch[~inp_ch.ED_adate_dt.isnull()]\n",
    "print(inp_ch.shape)\n",
    "inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'])\n",
    "inp_ch['ED_adate_dt'] = pd.to_datetime(inp_ch['ED_adate_dt'])\n",
    "inp_ch['IndexAttDate'] = pd.to_datetime(inp_ch['ED_adate_dt']).dt.date\n",
    "inp_ch['breq_dt'] = pd.to_datetime(inp_ch['breq_dt'])\n",
    "inp_ch['HOSP_FCC_dt'] = pd.to_datetime(inp_ch['HOSP_FCC_dt'])\n",
    "inp_ch['HOSP_FAS_dt'] = pd.to_datetime(inp_ch['HOSP_FAS_dt'])\n",
    "inp_ch['HOSP_FAS_dt'] = np.where(inp_ch['HOSP_FAS_dt'].isnull(), inp_ch['HOSP_FCC_dt'], inp_ch['HOSP_FAS_dt'])\n",
    "#inp_ch['ED_time_mins'] = (inp_ch['HOSP_adt'] - inp_ch['ED_adate_dt']) / pd.Timedelta(minutes=1)\n",
    "#inp_ch = inp_ch[inp_ch.ED_time_mins >= 0]\n",
    "print(inp_ch.shape)\n",
    "inp_ch['Sex_F'] = np.where(inp_ch.Sex == 'F', 1, 0)\n",
    "inp_ch['simd_dec'] = inp_ch['simd_dec'].astype(int)\n",
    "inp_ch = inp_ch.drop('Sex', axis=1)\n",
    "inp_ch = inp_ch.sort_values(['ppid', 'EpisodeNumber', 'HOSP_adt'])\n",
    "inp_ch = pd.get_dummies(inp_ch, columns=['arrival_mode', 'PresentingCondition'])\n",
    "inp_ch = inp_ch.rename(columns=lambda x: x.replace(' ', '_'))\n",
    "#### Set index date\n",
    "inp_ch['HOSP_adt_s'] = inp_ch['HOSP_adt']\n",
    "#inp_ch['HOSP_adt'] = inp_ch['ED_adate_dt']\n",
    "#inp_ch['AdmissionDate'] = pd.to_datetime(inp_ch['ED_adate_dt']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6984eb74-902d-47ec-a680-e16670a0f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set point of sampling\n",
    "inp_ch['coh_idx'] = 1\n",
    "inp_ch['HOSP_adt_s'] = inp_ch['HOSP_adt']\n",
    "inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'] + timedelta(hours=72))\n",
    "### Filter pts still in study\n",
    "inp_ch = inp_ch[inp_ch['HOSP_adt'] < inp_ch['HOSP_ddt']]\n",
    "print(inp_ch.shape)\n",
    "inp_ch = pd.merge(inp_ch, demo_data[['ppid', 'DateOfDeath']], how='left', on='ppid')\n",
    "inp_ch = inp_ch[(inp_ch['HOSP_adt'] < inp_ch['DateOfDeath'])|(inp_ch['DateOfDeath'].isna())]\n",
    "print(inp_ch.shape)\n",
    "#inp_ch['AdmissionDate'] = inp_ch['IndexAttDate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610072ad-8894-41a2-a298-be3cd165f00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5963d7-f72a-4c46-90fb-c6f6bbf87092",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = inp_ch.drop(['arrival_mode_M', 'arrival_mode_H', 'arrival_mode_C'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f018589-f64d-4cf6-aa02-e81103fb3cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f636aa5-fdc5-4f95-88fa-e06e2cb7e53d",
   "metadata": {},
   "source": [
    "#### Parse WardWatcher features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363def5c-ac06-4859-81c9-109cd77f755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ww_features(inp_ch, ww_adm, ww_hai, ww_howie, ww_ph, ww_sics,\n",
    "                   n_cohorts=10, window=15):\n",
    "    ### WW ADM\n",
    "    ww_adm = ww_adm[['ppid', 'CriticalCareUniqueID', 'Unit_Admit_Date', 'Unit_Admit_Time',\n",
    "                     'Unit_Disch_date', 'Unit_Disch_Time', 'ICNARC_1_Diag', 'ICNARC_4_Diag']].dropna()\n",
    "    ww_adm['CC_adate'] = pd.to_datetime(ww_adm['Unit_Admit_Date'].astype(str) + ' ' + ww_adm['Unit_Admit_Time'].astype(str), errors='coerce')\n",
    "    ww_adm['CC_ddate'] = pd.to_datetime(ww_adm['Unit_Disch_date'].astype(str) + ' ' + ww_adm['Unit_Disch_Time'].astype(str), errors='coerce')\n",
    "    ww_adm['ICNARC_1_Diag'] = ww_adm['ICNARC_1_Diag'].astype(int)\n",
    "    ww_adm['ICNARC_4_Diag'] = ww_adm['ICNARC_4_Diag'].astype(int)\n",
    "    ### Previous ICU admission reason\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 100570) & (ww_adm['ICNARC_1_Diag'] <= 100780), 'gastrointestinal', 'other')\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 101670) & (ww_adm['ICNARC_1_Diag'] <= 101850), 'gastrointestinal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 301050) & (ww_adm['ICNARC_1_Diag'] <= 301489), 'gastrointestinal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 301491) & (ww_adm['ICNARC_1_Diag'] <= 301495), 'gastrointestinal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 302780) & (ww_adm['ICNARC_1_Diag'] <= 302910), 'gastrointestinal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] == 308600), 'gastrointestinal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 308180) & (ww_adm['ICNARC_1_Diag'] <= 308190), 'gastrointestinal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 100220) & (ww_adm['ICNARC_1_Diag'] <= 100390), 'respiratory', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 101500) & (ww_adm['ICNARC_1_Diag'] <= 101570), 'respiratory', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] == 102180), 'respiratory', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 300440) & (ww_adm['ICNARC_1_Diag'] <= 300799), 'respiratory', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 309010) & (ww_adm['ICNARC_1_Diag'] <= 309020), 'respiratory', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 101500) & (ww_adm['ICNARC_1_Diag'] <= 101570), 'respiratory', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 100790) & (ww_adm['ICNARC_1_Diag'] <= 100870), 'renal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 101860) & (ww_adm['ICNARC_1_Diag'] <= 101960), 'renal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] == 301490), 'renal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 301500) & (ww_adm['ICNARC_1_Diag'] <= 301645), 'renal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 308300) & (ww_adm['ICNARC_1_Diag'] <= 308340), 'renal', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 100000) & (ww_adm['ICNARC_1_Diag'] <= 100210), 'cardiovascular', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 101240) & (ww_adm['ICNARC_1_Diag'] <= 101490), 'cardiovascular', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] >= 300010) & (ww_adm['ICNARC_1_Diag'] <= 300430), 'cardiovascular', ww_adm['ww_prev_syst_code'])\n",
    "    ww_adm['ww_prev_syst_code'] = np.where((ww_adm['ICNARC_1_Diag'] == 0), 'unk', ww_adm['ww_prev_syst_code'])\n",
    "    ### Previous surgery code\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] >= 302780) & (ww_adm['ICNARC_4_Diag'] <= 302910), 'gastrointestinal', 'other')\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] == 302670), 'cardiac', ww_adm['ww_prev_surg_code'])\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] >= 302680) & (ww_adm['ICNARC_4_Diag'] <= 302690), 'cardiac', ww_adm['ww_prev_surg_code'])\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] >= 308110) & (ww_adm['ICNARC_4_Diag'] <= 308120), 'cardiac', ww_adm['ww_prev_surg_code'])\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] >= 308160) & (ww_adm['ICNARC_4_Diag'] <= 308170), 'cardiac', ww_adm['ww_prev_surg_code'])\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] == 309000), 'cardiac', ww_adm['ww_prev_surg_code'])\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] >= 303120) & (ww_adm['ICNARC_4_Diag'] <= 303160), 'urological', ww_adm['ww_prev_surg_code'])\n",
    "    ww_adm['ww_prev_surg_code'] = np.where((ww_adm['ICNARC_4_Diag'] == 0), 'unk', ww_adm['ww_prev_surg_code'])\n",
    "    ww_adm = pd.get_dummies(ww_adm, columns=['ww_prev_syst_code', 'ww_prev_surg_code'])\n",
    "    ww_adm = ww_adm.drop(['Unit_Admit_Date', 'Unit_Admit_Time',\n",
    "                     'Unit_Disch_date', 'Unit_Disch_Time', 'ICNARC_4_Diag', 'ICNARC_1_Diag'], axis=1)\n",
    "    ### WW HAI\n",
    "    ww_hai = ww_hai.fillna(0)\n",
    "    ww_hai['ww_antimicr'] = np.where((ww_hai['Antimicrobials_ICU_Day1or2']==1)|(ww_hai['Antimicrobials_ICUAdmit']==1), 1, 0)\n",
    "    ww_hai['ww_surgery'] = np.where((ww_hai['Surgery_7Days_After']==1)|(ww_hai['Surgery_7Days_Prior']==1), 1, 0)\n",
    "    ww_hai = ww_hai.merge(ww_adm[['ppid', 'CriticalCareUniqueID', 'CC_adate', 'CC_ddate']], how='left', on=['ppid', 'CriticalCareUniqueID'])\n",
    "    ww_hai = ww_hai[ww_hai.CC_adate.notnull()]\n",
    "    ww_hai['CC_adate'] = pd.to_datetime(ww_hai['CC_adate'])\n",
    "    ww_hai = ww_hai[['ppid', 'CC_adate', 'ww_antimicr', 'ww_surgery', 'Trauma_Admission']].rename(columns={'Trauma_Admission': 'ww_trauma'})\n",
    "    ww_hai[['ww_antimicr', 'ww_surgery', 'ww_trauma']] = ww_hai[['ww_antimicr', 'ww_surgery', 'ww_trauma']].astype(np.int8)\n",
    "    ### WW HOWIE\n",
    "    ww_howie = ww_howie.fillna(0)\n",
    "    ww_howie = ww_howie[['ppid', 'CriticalCareUniqueID', 'Date', 'Resp_Manage_Ventilator', 'Resp_Manage_CPAP', 'Resp_Manage_O2_Less50pc',\n",
    "    'Airway_Manage_ETT', 'Multiple_IV_VA_Drugs', 'Blood_Purify', 'ICP_Monitor', 'Neuro_OneToOne', 'CNS_Depression',\n",
    "    'Nutrition_Parenteral', 'Nutrition_Enteral']].rename(columns={'Date': 'MeasureDate',\n",
    "                                                                  'Resp_Manage_Ventilator': 'ww_iv_need', \n",
    "                                                                  'Resp_Manage_CPAP': 'ww_cpap_need',\n",
    "                                                                  'Resp_Manage_O2_Less50pc': 'ww_02_b50pc',\n",
    "                                                                  'Airway_Manage_ETT': 'ww_airway_eti',\n",
    "                                                                  'Multiple_IV_VA_Drugs': 'ww_multi_iv_drugs',\n",
    "                                                                  'Blood_Purify': 'ww_ac_renal_repl',\n",
    "                                                                  'ICP_Monitor': 'ww_inv_neuro_monitor',\n",
    "                                                                  'Neuro_OneToOne': 'ww_neuro_1to1_need',\n",
    "                                                                  'CNS_Depression': 'ww_cns_depression',\n",
    "                                                                  'Nutrition_Parenteral': 'ww_nutr_par_need',\n",
    "                                                                  'Nutrition_Enteral': 'ww_nutr_ent_need'})\n",
    "    ww_howie = ww_howie.merge(ww_adm[['ppid', 'CriticalCareUniqueID', 'CC_adate', 'CC_ddate']], how='left', on=['ppid', 'CriticalCareUniqueID'])\n",
    "    ww_howie = ww_howie[ww_howie.CC_adate.notnull()]\n",
    "    ww_howie = ww_howie[ww_howie.MeasureDate.notnull()]\n",
    "    ww_howie['CC_adate'] = pd.to_datetime(ww_howie['CC_adate'])\n",
    "    ww_howie['MeasureDate'] = pd.to_datetime(ww_howie['MeasureDate'])\n",
    "    ### WW Physiology\n",
    "    ww_ph = ww_ph[['ppid', 'CriticalCareUniqueID', 'AP2']]\n",
    "    ww_ph = ww_ph.merge(ww_adm[['ppid', 'CriticalCareUniqueID', 'CC_adate', 'CC_ddate']], how='left', on=['ppid', 'CriticalCareUniqueID'])\n",
    "    ww_ph = ww_ph[ww_ph.CC_adate.notnull()]\n",
    "    ww_ph['CC_adate'] = pd.to_datetime(ww_ph['CC_adate'])\n",
    "    ww_ph['AP2'] = ww_ph['AP2'].astype(int)\n",
    "    ww_ph = ww_ph.rename(columns={'AP2': 'ww_AP2'})\n",
    "    ### WW SICS\n",
    "    ww_sics = ww_sics[['ppid', 'CriticalCareUniqueID', 'Vent_days']]\n",
    "    ww_sics = ww_sics.merge(ww_adm[['ppid', 'CriticalCareUniqueID', 'CC_adate', 'CC_ddate']], how='left', on=['ppid', 'CriticalCareUniqueID'])\n",
    "    ww_sics = ww_sics[ww_sics.CC_adate.notnull()]\n",
    "    ww_sics['CC_adate'] = pd.to_datetime(ww_ph['CC_adate'])\n",
    "    ww_sics['Vent_days'] = ww_sics['Vent_days'].astype(int)\n",
    "    ww_sics = ww_sics[ww_sics['Vent_days']<100]\n",
    "    ww_sics = ww_sics.rename(columns={'Vent_days': 'ww_vent_days'})\n",
    "    ### Pipeline\n",
    "    full_coh = pd.DataFrame()\n",
    "    inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'])\n",
    "    for i in range(1, n_cohorts+1, window):\n",
    "        print('Processing cohort:', i)\n",
    "        cur_coh = inp_ch[inp_ch['coh_idx']==i]\n",
    "        #pr_start = inp_ch[inp_ch['coh_idx']==i]['HOSP_iadate']\n",
    "        ww_adm_ch = pd.merge(ww_adm, cur_coh[['ppid', 'EpisodeNumber', 'HOSP_adt']], how='left', on=['ppid'])\n",
    "        ww_adm_ch = ww_adm_ch[(ww_adm_ch['CC_adate'] < (ww_adm_ch['HOSP_adt'] + timedelta(hours=0)))&(ww_adm_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        ww_adm_ch = ww_adm_ch.sort_values(['ppid', 'CC_adate']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        ww_sics_ch = pd.merge(ww_sics, cur_coh[['ppid', 'EpisodeNumber', 'HOSP_adt']], how='left', on=['ppid'])\n",
    "        ww_sics_ch = ww_sics_ch[(ww_sics_ch['CC_adate'] < (ww_sics_ch['HOSP_adt'] + timedelta(hours=0)))&(ww_sics_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        ww_sics_ch = ww_sics_ch.sort_values(['ppid', 'CC_adate']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        ww_ph_ch = pd.merge(ww_ph, cur_coh[['ppid', 'EpisodeNumber', 'HOSP_adt']], how='left', on=['ppid'])\n",
    "        ww_ph_ch = ww_ph_ch[(ww_ph_ch['CC_adate'] < (ww_ph_ch['HOSP_adt'] + timedelta(hours=0)))&(ww_ph_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        ww_ph_ch = ww_ph_ch.sort_values(['ppid', 'EpisodeNumber', 'CC_adate']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        ww_howie_ch = pd.merge(ww_howie, cur_coh[['ppid', 'EpisodeNumber', 'HOSP_adt']], how='left', on=['ppid'])\n",
    "        ww_howie_ch = ww_howie_ch[(ww_howie_ch['CC_adate'] < (ww_howie_ch['HOSP_adt'] + timedelta(hours=0)))&(ww_howie_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        ww_howie_ch = ww_howie_ch[(ww_howie_ch['MeasureDate'] < (ww_howie_ch['HOSP_adt'] + timedelta(hours=0)))]\n",
    "        ww_howie_ch = ww_howie_ch.sort_values(['ppid', 'EpisodeNumber', 'CC_adate']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        ww_hai_ch = pd.merge(ww_hai, cur_coh[['ppid', 'EpisodeNumber', 'HOSP_adt']], how='left', on=['ppid'])\n",
    "        ww_hai_ch = ww_hai_ch[(ww_hai_ch['CC_adate'] < (ww_hai_ch['HOSP_adt'] + timedelta(hours=0)))&(ww_hai_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        ww_hai_ch = ww_hai_ch.sort_values(['ppid', 'EpisodeNumber', 'CC_adate']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        cur_coh = pd.merge(cur_coh, ww_adm_ch.drop(['CriticalCareUniqueID', 'CC_adate', 'CC_ddate'], axis=1), how='left', on=['ppid', 'EpisodeNumber', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, ww_howie_ch.drop(['MeasureDate', 'CriticalCareUniqueID', 'CC_adate', 'CC_ddate'], axis=1), how='left', on=['ppid', 'EpisodeNumber', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, ww_hai_ch.drop(['CC_adate'], axis=1), how='left', on=['ppid', 'EpisodeNumber', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, ww_ph_ch.drop(['CriticalCareUniqueID', 'CC_adate', 'CC_ddate'], axis=1), how='left', on=['ppid', 'EpisodeNumber', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, ww_sics_ch.drop(['CriticalCareUniqueID', 'CC_adate', 'CC_ddate'], axis=1), how='left', on=['ppid', 'EpisodeNumber', 'HOSP_adt'])\n",
    "        cur_coh[['ww_iv_need', 'ww_cpap_need', 'ww_02_b50pc', 'ww_airway_eti',\n",
    "       'ww_multi_iv_drugs', 'ww_ac_renal_repl', 'ww_inv_neuro_monitor',\n",
    "       'ww_cns_depression', 'ww_neuro_1to1_need', 'ww_nutr_par_need',\n",
    "       'ww_nutr_ent_need', 'ww_antimicr', 'ww_surgery', 'ww_trauma']] = cur_coh[['ww_iv_need', 'ww_cpap_need', 'ww_02_b50pc', 'ww_airway_eti',\n",
    "       'ww_multi_iv_drugs', 'ww_ac_renal_repl', 'ww_inv_neuro_monitor',\n",
    "       'ww_cns_depression', 'ww_neuro_1to1_need', 'ww_nutr_par_need',\n",
    "       'ww_nutr_ent_need', 'ww_antimicr', 'ww_surgery', 'ww_trauma']].round().fillna(0).astype(np.int8)\n",
    "        cur_coh[[col for col in cur_coh if 'ww_prev' in col]] = cur_coh[[col for col in cur_coh if 'ww_prev' in col]].fillna(0).astype(np.int8)\n",
    "        cur_coh[['ww_AP2', 'ww_vent_days']] = cur_coh[['ww_AP2', 'ww_vent_days']].round().fillna(0).astype(np.int16)\n",
    "        full_coh = pd.concat([full_coh, cur_coh], axis=0)\n",
    "\n",
    "    return full_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f412386d-e7b9-4561-8582-fde37058c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = get_ww_features(inp_ch, ww_adm, ww_hai, ww_howie, ww_ph, ww_sics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d33d2-558f-4cf1-ac18-442fdb303b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd736397-2c56-47f0-8651-4d788c5137f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82ba076-ecd6-4890-b2a0-babfba7282a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inp_ch.columns:\n",
    "    if 'ww_' in col:\n",
    "        print(inp_ch[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d717a4e6-0d50-4656-9132-d8126771b733",
   "metadata": {},
   "source": [
    "#### Parse TrakQ features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8a5cfe-b3db-447d-8f71-939308d8b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trakq_features(inp_ch, trq_4at, trq_BBF, trq_falls, trq_mobility,\n",
    "                   trq_MRSA, trq_MUST, trq_nutr, trq_RUB, trq_wt, n_cohorts=10, window=15):\n",
    "    ### TRQ 4AT\n",
    "    trq_4at = trq_4at[['ppid', 'DateOfAssessment', '4AT score']].rename(columns={'4AT score': 'trQ_4at'})\n",
    "    trq_4at['DateOfAssessment'] = pd.DatetimeIndex(pd.to_datetime(trq_4at['DateOfAssessment'])).tz_localize(None)\n",
    "    \n",
    "    ### TRQ BBF\n",
    "    cat_dict = {'Y': 1, 'N': 0}\n",
    "    trq_BBF = trq_BBF[['ppid', 'DateIdentified', 'Is_the_patientâs_bladder_drained_by_a_urinary_catheter?_Code',\n",
    "                      'Is_the_patient_incontinent_of_urine?_Code', 'Dysuria_(pain_passing_urine)?_Code',\n",
    "                      'Frequency_(greater_than_6_times_per_day)?_Code', 'Nocturia_(greater_than_twice_per_night)?_Code',\n",
    "                      'Is_the_patient_incontinent_of_faeces?_Code', 'Constipation?_Code', 'Diarrhoea?_Code',\n",
    "                      'Blood_in_stools?_Code', 'Is_the_patient_on_any_current_medication_for_bowels?_Code']].fillna('N')\n",
    "\n",
    "    for rc in ['Is_the_patientâs_bladder_drained_by_a_urinary_catheter?_Code',\n",
    "                      'Is_the_patient_incontinent_of_urine?_Code', 'Dysuria_(pain_passing_urine)?_Code',\n",
    "                      'Frequency_(greater_than_6_times_per_day)?_Code', 'Nocturia_(greater_than_twice_per_night)?_Code',\n",
    "                      'Is_the_patient_incontinent_of_faeces?_Code', 'Constipation?_Code', 'Diarrhoea?_Code',\n",
    "                      'Blood_in_stools?_Code', 'Is_the_patient_on_any_current_medication_for_bowels?_Code']:\n",
    "        trq_BBF[rc] = trq_BBF[rc].map(cat_dict).astype(np.int8)\n",
    "    \n",
    "    trq_BBF = trq_BBF.rename(\n",
    "        columns={'Is_the_patientâs_bladder_drained_by_a_urinary_catheter?_Code': 'trQ_bwm_urinary_catheterisation',\n",
    "                'Is_the_patient_incontinent_of_urine?_Code': 'trQ_bwm_urinary_incontinence',\n",
    "                'Dysuria_(pain_passing_urine)?_Code': 'trQ_bwm_dysuria',\n",
    "                'Frequency_(greater_than_6_times_per_day)?_Code': 'trQ_bwm_>6times_per_day',\n",
    "                'Nocturia_(greater_than_twice_per_night)?_Code': 'trQ_bwm_nocturia_>2_per_night',\n",
    "                'Is_the_patient_incontinent_of_faeces?_Code': 'trQ_bwm_faeces_incontinence',\n",
    "                'Constipation?_Code': 'trQ_bwm_constipation',\n",
    "                'Diarrhoea?_Code': 'trQ_bwm_diarrhoea',\n",
    "                'Blood_in_stools?_Code': 'trQ_bwm_blood_in_stools',\n",
    "                'Is_the_patient_on_any_current_medication_for_bowels?_Code': 'trQ_bwm_medication'})\n",
    "    trq_BBF['DateIdentified'] = pd.to_datetime(trq_BBF['DateIdentified'])\n",
    "    \n",
    "    ### TRQ FALLS\n",
    "    trq_falls = trq_falls[['ppid', 'DateOfAssessment', 'Has_the_patient_fallen_in_the_last_6_months_code',\n",
    "                      'Based_on_your_clinical_judgement_is_this_patient_at_high_risk_of_falls_code']].fillna('N')\n",
    "    for rc in ['Has_the_patient_fallen_in_the_last_6_months_code',\n",
    "                      'Based_on_your_clinical_judgement_is_this_patient_at_high_risk_of_falls_code']:\n",
    "        trq_falls[rc] = trq_falls[rc].map(cat_dict).astype(np.int8)\n",
    "    trq_falls = trq_falls.rename(\n",
    "        columns={'Has_the_patient_fallen_in_the_last_6_months_code': 'trQ_falls_within_6_months',\n",
    "                'Based_on_your_clinical_judgement_is_this_patient_at_high_risk_of_falls_code': 'trQ_falls_clinical_risk'})\n",
    "    trq_falls['DateOfAssessment'] = pd.DatetimeIndex(pd.to_datetime(trq_falls['DateOfAssessment'])).tz_localize(None)\n",
    "    \n",
    "    ### TRQ MOBILITY\n",
    "    trq_mobility = trq_mobility[['ppid', 'DateOfAssessment', 'Walking', 'Toileting', 'Bathing/showering',\n",
    "       'Rolling in bed', 'Moving up the bed',\n",
    "       'Getting out of bed', 'Getting into bed',\n",
    "       'Sit to stand to sit', 'Lateral transfers',\n",
    "       'Up from floor']].fillna('NA_BREST')\n",
    "    trq_mobility = trq_mobility.rename(\n",
    "        columns={'Walking': 'trQ_mobility_walking',\n",
    "                'Toileting': 'trQ_mobility_toileting',\n",
    "                'Bathing/showering': 'trQ_mobility_bathing',\n",
    "                'Rolling in bed': 'trQ_mobility_bed_rolling',\n",
    "                'Moving up the bed': 'trQ_mobility_bed_moveup',\n",
    "                'Getting out of bed': 'trQ_mobility_bed_out',\n",
    "                'Getting into bed': 'trQ_mobility_bed_in',\n",
    "                'Sit to stand to sit': 'trQ_mobility_sss',\n",
    "                'Lateral transfers': 'trQ_mobility_lateral',\n",
    "                'Up from floor': 'trQ_mobility_floorup'})\n",
    "    trq_mobility['DateOfAssessment'] = pd.DatetimeIndex(pd.to_datetime(trq_mobility['DateOfAssessment'])).tz_localize(None)\n",
    "    for col in trq_mobility.columns:\n",
    "        if 'trQ_mobility_' in col:\n",
    "            trq_mobility[col] = trq_mobility[col].fillna('Not assessed').astype(str)\n",
    "            trq_mobility[col] = np.where(trq_mobility[col].str.contains('Independent'), 'INDEPENDENT',\n",
    "                                         np.where(trq_mobility[col].str.contains('Not applicable'), \n",
    "                                                       'BED_REST', \n",
    "                                                       np.where((trq_mobility[col].str.contains('Assistance'))|\n",
    "                                                       (trq_mobility[col].str.contains('Zimmer / Rollator'))|\n",
    "                                                       (trq_mobility[col].str.contains('Stick'))|\n",
    "                                                       (trq_mobility[col].str.contains('Crutches'))| \n",
    "                                                       (trq_mobility[col].str.contains('Glidesheet'))|\n",
    "                                                       (trq_mobility[col].str.contains('lifting hoist'))|\n",
    "                                                       (trq_mobility[col].str.contains('Stand aid'))|\n",
    "                                                        (trq_mobility[col].str.contains('Patient turning device'))|\n",
    "                                                        (trq_mobility[col].str.contains('Commode'))|\n",
    "                                                        (trq_mobility[col].str.contains('Bedpan'))|\n",
    "                                                        (trq_mobility[col].str.contains('Bathing hoist'))|\n",
    "                                                        (trq_mobility[col].str.contains('Shower chair'))|\n",
    "                                                        (trq_mobility[col].str.contains('Lateral transfer board'))|\n",
    "                                                        (trq_mobility[col].str.contains('Hoverjack'))|\n",
    "                                                        (trq_mobility[col].str.contains('Lifting cushion')),\n",
    "                                                       'ASSISTANCE', 'OTHER')))\n",
    "    ### TRQ MRSA\n",
    "    trq_MRSA = trq_MRSA[['ppid', 'DateIdentified', 'Does_the_patient_have_any_active_infection_prevention_and_control_alerts?_Code',\n",
    "                      'Has_the_patient_transferred_from_any_ward_or_care_home_with_suspected_or_confirmed_Norovirus?_Code', \n",
    "                        'Does_the_patient_present_with_respiratory_symptoms_+/-_fever?_Code',\n",
    "                      'Does_the_patient_have_a_rash_with_onset_in_the_last_24-48_hrs_+/-_fever_or_flu_like_symptoms?_Code',\n",
    "       'Has_the_patient_been_in_contact_with_any_infectious_diseases?_Code']].fillna('N')\n",
    "    for rc in ['Does_the_patient_have_any_active_infection_prevention_and_control_alerts?_Code',\n",
    "                      'Has_the_patient_transferred_from_any_ward_or_care_home_with_suspected_or_confirmed_Norovirus?_Code', \n",
    "                        'Does_the_patient_present_with_respiratory_symptoms_+/-_fever?_Code',\n",
    "                      'Does_the_patient_have_a_rash_with_onset_in_the_last_24-48_hrs_+/-_fever_or_flu_like_symptoms?_Code',\n",
    "       'Has_the_patient_been_in_contact_with_any_infectious_diseases?_Code']:\n",
    "        trq_MRSA[rc] = trq_MRSA[rc].map(cat_dict).astype(np.int8)\n",
    "    trq_MRSA = trq_MRSA.rename(\n",
    "        columns={'Does_the_patient_have_any_active_infection_prevention_and_control_alerts?_Code': 'trQ_mrsa_infection_prevention',\n",
    "                'Has_the_patient_transferred_from_any_ward_or_care_home_with_suspected_or_confirmed_Norovirus?_Code': 'trQ_mrsa_transfer_with_norovirus',\n",
    "                'Does_the_patient_present_with_respiratory_symptoms_+/-_fever?_Code': 'trQ_mrsa_resp_or_fever',\n",
    "                'Does_the_patient_have_a_rash_with_onset_in_the_last_24-48_hrs_+/-_fever_or_flu_like_symptoms?_Code': 'trQ_mrsa_rash_fever_or_flu',\n",
    "                'Has_the_patient_been_in_contact_with_any_infectious_diseases?_Code': 'trQ_mrsa_infectious_diseases_contact'})\n",
    "    trq_MRSA['DateIdentified'] = pd.to_datetime(trq_MRSA['DateIdentified'])\n",
    "\n",
    "    ### TRQ Nutritional Profile\n",
    "    trq_nutr = trq_nutr[['ppid', 'DateIdentified', 'Does_the_patient_have_food_allergies?_Code',\n",
    "       'Does_the_patient_have_any_swallowing_difficulties?_Code']].fillna('N')\n",
    "    for rc in ['Does_the_patient_have_food_allergies?_Code',\n",
    "       'Does_the_patient_have_any_swallowing_difficulties?_Code']:\n",
    "        trq_nutr[rc] = trq_nutr[rc].map(cat_dict).astype(np.int8)\n",
    "        \n",
    "    trq_nutr = trq_nutr.rename(\n",
    "        columns={'Does_the_patient_have_food_allergies?_Code': 'trQ_nutr_food_allergies',\n",
    "                'Does_the_patient_have_any_swallowing_difficulties?_Code': 'trQ_nutr_swallowing_difficulty'})\n",
    "    trq_nutr['DateIdentified'] = pd.to_datetime(trq_nutr['DateIdentified'])\n",
    "\n",
    "    ### TRQ Bedrails\n",
    "    trq_RUB = trq_RUB[['ppid', 'DateOfAssessment', \n",
    "                       'An_initial_documented_nursing_and_falls_risk_assessment_is_made_within_24_hours_of_admission_Code',\n",
    "       'Is_the_patient_at_risk_of_falling_out_of_bed?_Code']].fillna('N')\n",
    "    for rc in ['An_initial_documented_nursing_and_falls_risk_assessment_is_made_within_24_hours_of_admission_Code',\n",
    "       'Is_the_patient_at_risk_of_falling_out_of_bed?_Code']:\n",
    "        trq_RUB[rc] = trq_RUB[rc].map(cat_dict).astype(np.int8)\n",
    "    trq_RUB = trq_RUB.rename(\n",
    "        columns={'An_initial_documented_nursing_and_falls_risk_assessment_is_made_within_24_hours_of_admission_Code': 'trQ_rub_nursing_falls_risk_assessment',\n",
    "                'Is_the_patient_at_risk_of_falling_out_of_bed?_Code': 'trQ_rub_at_risk_of_bed_fall'})\n",
    "    trq_RUB['DateOfAssessment'] = pd.DatetimeIndex(pd.to_datetime(trq_RUB['DateOfAssessment'])).tz_localize(None)\n",
    "\n",
    "    ### TRQ Pressure Ulcers (waterlow)\n",
    "    trq_wt = trq_wt[['ppid', 'DateOfAssessment', 'Score']].rename(columns={'Score': 'trQ_waterlow_score'})\n",
    "    trq_wt['DateOfAssessment'] = pd.DatetimeIndex(pd.to_datetime(trq_wt['DateOfAssessment'])).tz_localize(None)\n",
    "\n",
    "    ### TRQ MUST score\n",
    "    trq_MUST = trq_MUST[['ppid', 'DateOfAssessment', 'Total score']].rename(columns={'Total score': 'trQ_MUST_score'})\n",
    "    trq_MUST['DateOfAssessment'] = pd.DatetimeIndex(pd.to_datetime(trq_MUST['DateOfAssessment'])).tz_localize(None)\n",
    "\n",
    "    ### Pipeline\n",
    "    full_coh = pd.DataFrame()\n",
    "    inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'])\n",
    "    inp_ch['AdmissionDate'] = pd.to_datetime(inp_ch['AdmissionDate'])\n",
    "    for i in range(1, n_cohorts+1, window):\n",
    "        print('Processing cohort:', i)\n",
    "        cur_coh = inp_ch[inp_ch['coh_idx']==i]\n",
    "        #pr_start = inp_ch[inp_ch['coh_idx']==i]['HOSP_iadate']\n",
    "        trq_4at_ch = pd.merge(trq_4at, cur_coh[['ppid', 'HOSP_adt']], how='left', on='ppid')\n",
    "        trq_4at_ch = trq_4at_ch[((trq_4at_ch['HOSP_adt'] + timedelta(hours=0)) >= trq_4at_ch['DateOfAssessment'])&(trq_4at_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_4at_ch = trq_4at_ch.sort_values(['ppid', 'DateOfAssessment']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        trq_BBF_ch = pd.merge(trq_BBF, cur_coh[['ppid', 'AdmissionDate']], how='left', on='ppid')\n",
    "        trq_BBF_ch = trq_BBF_ch[((trq_BBF_ch['AdmissionDate'] + timedelta(days=0)) >= trq_BBF_ch['DateIdentified'])&(trq_BBF_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_BBF_ch = trq_BBF_ch.sort_values(['ppid', 'DateIdentified']).drop_duplicates(['ppid', 'AdmissionDate'], keep='last')\n",
    "        trq_falls_ch = pd.merge(trq_falls, cur_coh[['ppid', 'HOSP_adt']], how='left', on='ppid')\n",
    "        trq_falls_ch = trq_falls_ch[((trq_falls_ch['HOSP_adt'] + timedelta(hours=0)) >= trq_falls_ch['DateOfAssessment'])&(trq_falls_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_falls_ch = trq_falls_ch.sort_values(['ppid', 'DateOfAssessment']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        trq_mobility_ch = pd.merge(trq_mobility, cur_coh[['ppid', 'HOSP_adt']], how='left', on='ppid')\n",
    "        trq_mobility_ch = trq_mobility_ch[((trq_mobility_ch['HOSP_adt'] + timedelta(hours=0)) >= trq_mobility_ch['DateOfAssessment'])&(trq_mobility_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_mobility_ch = trq_mobility_ch.sort_values(['ppid', 'DateOfAssessment']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        trq_MRSA_ch = pd.merge(trq_MRSA, cur_coh[['ppid', 'AdmissionDate']], how='left', on='ppid')\n",
    "        trq_MRSA_ch = trq_MRSA_ch[((trq_MRSA_ch['AdmissionDate'] + timedelta(days=0)) >= trq_MRSA_ch['DateIdentified'])&(trq_MRSA_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_MRSA_ch = trq_MRSA_ch.sort_values(['ppid', 'DateIdentified']).drop_duplicates(['ppid', 'AdmissionDate'], keep='last')\n",
    "        trq_nutr_ch = pd.merge(trq_nutr, cur_coh[['ppid', 'AdmissionDate']], how='left', on='ppid')\n",
    "        trq_nutr_ch = trq_nutr_ch[((trq_nutr_ch['AdmissionDate'] + timedelta(days=0)) >= trq_nutr_ch['DateIdentified'])&(trq_nutr_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_nutr_ch = trq_nutr_ch.sort_values(['ppid', 'DateIdentified']).drop_duplicates(['ppid', 'AdmissionDate'], keep='last')\n",
    "        trq_RUB_ch = pd.merge(trq_RUB, cur_coh[['ppid', 'HOSP_adt']], how='left', on='ppid')\n",
    "        trq_RUB_ch = trq_RUB_ch[((trq_RUB_ch['HOSP_adt'] + timedelta(hours=0)) >= trq_RUB_ch['DateOfAssessment'])&(trq_RUB_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_RUB_ch = trq_RUB_ch.sort_values(['ppid', 'DateOfAssessment']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        trq_wt_ch = pd.merge(trq_wt, cur_coh[['ppid', 'HOSP_adt']], how='left', on='ppid')\n",
    "        trq_wt_ch = trq_wt_ch[((trq_wt_ch['HOSP_adt'] + timedelta(hours=0)) >= trq_wt_ch['DateOfAssessment'])&(trq_wt_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_wt_ch = trq_wt_ch.sort_values(['ppid', 'DateOfAssessment']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        trq_MUST_ch = pd.merge(trq_MUST, cur_coh[['ppid', 'HOSP_adt']], how='left', on='ppid')\n",
    "        trq_MUST_ch = trq_MUST_ch[((trq_MUST_ch['HOSP_adt'] + timedelta(hours=0)) >= trq_MUST_ch['DateOfAssessment'])&(trq_MUST_ch['ppid'].isin(inp_ch['ppid'].unique().tolist()))]\n",
    "        trq_MUST_ch = trq_MUST_ch.sort_values(['ppid', 'DateOfAssessment']).drop_duplicates(['ppid', 'HOSP_adt'], keep='last')\n",
    "        \n",
    "        \n",
    "        cur_coh = pd.merge(cur_coh, trq_4at_ch.drop(['DateOfAssessment'], axis=1), how='left', on=['ppid', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_BBF_ch.drop(['DateIdentified'], axis=1), how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_falls_ch.drop(['DateOfAssessment'], axis=1), how='left', on=['ppid', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_mobility_ch.drop(['DateOfAssessment'], axis=1), how='left', on=['ppid', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_nutr_ch.drop(['DateIdentified'], axis=1), how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_MRSA_ch.drop(['DateIdentified'], axis=1), how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_RUB_ch.drop(['DateOfAssessment'], axis=1), how='left', on=['ppid', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_wt_ch.drop(['DateOfAssessment'], axis=1), how='left', on=['ppid', 'HOSP_adt'])\n",
    "        cur_coh = pd.merge(cur_coh, trq_MUST_ch.drop(['DateOfAssessment'], axis=1), how='left', on=['ppid', 'HOSP_adt'])\n",
    "        ## Fill NAs\n",
    "        for col in ['trQ_bwm_urinary_catheterisation',\n",
    "       'trQ_bwm_urinary_incontinence', 'trQ_bwm_dysuria',\n",
    "       'trQ_bwm_>6times_per_day', 'trQ_bwm_nocturia_>2_per_night',\n",
    "       'trQ_bwm_faeces_incontinence', 'trQ_bwm_constipation',\n",
    "       'trQ_bwm_diarrhoea', 'trQ_bwm_blood_in_stools', 'trQ_bwm_medication',\n",
    "       'trQ_falls_within_6_months', 'trQ_falls_clinical_risk', 'trQ_nutr_food_allergies',\n",
    "       'trQ_nutr_swallowing_difficulty', 'trQ_mrsa_infection_prevention',\n",
    "       'trQ_mrsa_transfer_with_norovirus', 'trQ_mrsa_resp_or_fever',\n",
    "       'trQ_mrsa_rash_fever_or_flu', 'trQ_mrsa_infectious_diseases_contact',\n",
    "       'trQ_rub_nursing_falls_risk_assessment', 'trQ_rub_at_risk_of_bed_fall']:\n",
    "            cur_coh[col] = cur_coh[col].fillna(0).astype(np.int8)\n",
    "\n",
    "        for col in ['trQ_mobility_walking', 'trQ_mobility_toileting',\n",
    "       'trQ_mobility_bathing', 'trQ_mobility_bed_rolling',\n",
    "       'trQ_mobility_bed_moveup', 'trQ_mobility_bed_out',\n",
    "       'trQ_mobility_bed_in', 'trQ_mobility_sss', 'trQ_mobility_lateral',\n",
    "       'trQ_mobility_floorup']:\n",
    "            cur_coh[col] = cur_coh[col].fillna('NA').astype('category')\n",
    "            cur_coh = pd.get_dummies(cur_coh, columns=[col])\n",
    "\n",
    "        for col in ['trQ_4at', 'trQ_waterlow_score', 'trQ_MUST_score']:\n",
    "            cur_coh[col] = cur_coh[col].fillna(-1).astype(np.int16)\n",
    "\n",
    "        for col in cur_coh.columns:\n",
    "            if 'trQ_mobility' in col:\n",
    "                cur_coh[col] = cur_coh[col].astype(np.int8)\n",
    "        \n",
    "        full_coh = pd.concat([full_coh, cur_coh], axis=0)\n",
    "\n",
    "    return full_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4337c-2c06-46ae-a089-3344aab6934d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = get_trakq_features(inp_ch, trq_4at, trq_BBF, trq_falls, trq_mobility,\n",
    "                   trq_MRSA, trq_MUST, trq_nutr, trq_RUB, trq_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236bb8a-bb4f-44ae-a1e7-b6ad3a0145cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5fb6ff-f8ff-4b8c-bbb0-e6e4222e14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540c8774-de7a-462c-8570-16320143516f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in inp_ch.columns:\n",
    "    if 'trQ_' in col:\n",
    "        print(inp_ch[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600630b2-51f9-488e-9fbd-2fb6b10daab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape, inp_ch.ppid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0225445-c7c7-40d0-b993-c8e456ed439b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecbdc9f-2797-487a-9e62-9c4f57c7550e",
   "metadata": {},
   "source": [
    "#### Lab tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e8933-58b7-40b9-9a6c-406020f004e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f068993c-dd92-425f-ab00-0ae69b636195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get chunk size split for loading data into batches\n",
    "total_rows = sum(1 for _ in open('')) - 1\n",
    "chunk_size = total_rows // 4\n",
    "print(chunk_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1c6cb4-f391-4dd5-801b-6fdf6ce89c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_idx = 0\n",
    "term = 0\n",
    "for chunk in pd.read_csv('', sep='\\t', low_memory=False,\n",
    "                        chunksize=chunk_size):\n",
    "    if c_idx == term:\n",
    "        labs_data = chunk\n",
    "        break\n",
    "    c_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb909f3-0107-431c-a45b-5ab46e32eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa340df-e929-4c49-84fa-3a157ccf40af",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8805f-58a7-48f2-b5b7-524071caf1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_data.Status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c0e43-c71e-4ae4-8ee5-ff3a3bfa3e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct eGFR\n",
    "labs_data['RangeMin'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMin'].isnull()), '60.0',\n",
    "                                 labs_data['RangeMin'])\n",
    "labs_data['RangeMax'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMax'].isnull()), '150.0',\n",
    "                                 labs_data['RangeMax'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60.0'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='Not Indicated'), '61.0',\n",
    "                                 labs_data['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4179eb-330f-4459-aaea-0d20628facef",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Helper-functions\n",
    "def adjust_values(val):\n",
    "    try:\n",
    "        if '>' in val:\n",
    "            return float(val[1:]) + 1\n",
    "        elif '<' in val:\n",
    "            return float(val[1:]) - 1\n",
    "        else:\n",
    "            return val\n",
    "    except ValueError:\n",
    "        return val\n",
    "\n",
    "def get_normal_values_h(bloods_data):\n",
    "    if bloods_data.Value > bloods_data.RangeMax:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_normal_values_l(bloods_data):\n",
    "    if bloods_data.Value < bloods_data.RangeMin:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prep_labs(lab_set, inp_ch):\n",
    "    labs_sel = lab_set[lab_set.ppid.isin(inp_ch.ppid.unique())]\n",
    "    labs_sel = labs_sel[labs_sel['Status'] == 'A']\n",
    "    labs_sel = labs_sel[['ppid', 'SpecimenCollectionDate', 'SpecimenCollectionTime', 'Value', 'TestItem', 'RangeMin', 'RangeMax']]\n",
    "    labs_sel['SpecimenCollectionDate'] = pd.to_datetime(labs_sel['SpecimenCollectionDate'].astype(str) + ' ' + labs_sel['SpecimenCollectionTime'].astype(str), \n",
    "                                                        errors='coerce')\n",
    "    labs_sel = labs_sel[labs_sel.Value.notnull()]\n",
    "    labs_sel['Value'] = labs_sel['Value'].apply(adjust_values)\n",
    "    labs_sel['Value'] = pd.to_numeric(labs_sel['Value'], errors='coerce')\n",
    "    labs_sel['RangeMin'] = pd.to_numeric(labs_sel['RangeMin'], errors='coerce')\n",
    "    labs_sel['RangeMax'] = pd.to_numeric(labs_sel['RangeMax'], errors='coerce')\n",
    "    labs_sel['TestItem'] = labs_sel['TestItem'].astype(str).str.strip()\n",
    "    print(labs_sel.shape)\n",
    "    labs_sel.dropna(subset=['ppid', 'SpecimenCollectionDate', 'SpecimenCollectionTime', 'TestItem'], inplace=True)\n",
    "    print(labs_sel.shape)\n",
    "    return labs_sel\n",
    "\n",
    "def get_lab_features(labs_sel, inp_ch, n_cohorts=10, window=15, \n",
    "                     day_col='_days', rec_col='_recorded', nor_col='_normal_low', nor_col2='_normal_high',\n",
    "                    val_col='_value', rm_col='_rmean', rs_col='_rstd'):\n",
    "    ### Pipeline\n",
    "    full_coh = pd.DataFrame()\n",
    "    inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'])\n",
    "    inp_ch['AdmissionDate'] = pd.to_datetime(inp_ch['AdmissionDate'])\n",
    "    for i in range(1, n_cohorts+1, window):\n",
    "        print('Processing cohort:', i)\n",
    "        cur_coh = inp_ch[inp_ch['coh_idx']==i]\n",
    "        for test_item in labs_sel.TestItem.unique():\n",
    "            print('Processing features for:', test_item)\n",
    "            labs_sel_test = labs_sel[labs_sel['TestItem'] == test_item]\n",
    "            labs_sel_test = pd.merge(labs_sel_test, cur_coh[['ppid', 'HOSP_adt']], how='left', on='ppid')\n",
    "            labs_sel_test = labs_sel_test[((labs_sel_test['HOSP_adt'] + timedelta(hours=0)) >= labs_sel_test['SpecimenCollectionDate'])&(labs_sel_test.ppid.isin(cur_coh.ppid.unique()))]\n",
    "            #### Simple moving average over 365 days\n",
    "            labs_sel_test_t = labs_sel_test[labs_sel_test['SpecimenCollectionDate'] >= (labs_sel_test['HOSP_adt'] - timedelta(days=365))]\n",
    "            rstd = pd.DataFrame(labs_sel_test_t.groupby(['ppid'])['Value'].std()).rename(columns={'Value':'rstd'})\n",
    "            rmean = pd.DataFrame(labs_sel_test_t.groupby(['ppid'])['Value'].mean()).rename(columns={'Value':'rmean'})\n",
    "            labs_sel_test = pd.merge(labs_sel_test, rmean, how='left', on=['ppid'])\n",
    "            labs_sel_test = pd.merge(labs_sel_test, rstd, how='left', on=['ppid'])\n",
    "            #print(labs_sel_test.head())\n",
    "            labs_sel_test = labs_sel_test.sort_values(by=['ppid', 'SpecimenCollectionDate'], ascending=[True, False]).groupby(['ppid', 'HOSP_adt']).first().reset_index()\n",
    "            labs_sel_test['days_since_test'] = ((labs_sel_test['HOSP_adt'] + timedelta(hours=0)) - labs_sel_test['SpecimenCollectionDate']).dt.days.astype(np.int32)\n",
    "            labs_sel_test['recorded'] = np.where(labs_sel_test['Value'].isnull(), 0, 1)\n",
    "            labs_sel_test['normal_l'] = labs_sel_test.apply(get_normal_values_l, axis=1)\n",
    "            labs_sel_test['normal_h'] = labs_sel_test.apply(get_normal_values_h, axis=1)\n",
    "            print('Number of pts with test:', labs_sel_test[labs_sel_test.recorded==1].ppid.nunique())\n",
    "            labs_sel_test.rename(columns={'days_since_test': test_item.replace(' ', '_').lower() + day_col,\n",
    "                                          'Value': test_item.replace(' ', '_').lower() + val_col,\n",
    "                                          'recorded': test_item.replace(' ', '_').lower() + rec_col,\n",
    "                                          'normal_l': test_item.replace(' ', '_').lower() + nor_col,\n",
    "                                         'normal_h': test_item.replace(' ', '_').lower() + nor_col2,\n",
    "                                         'rmean': test_item.replace(' ', '_').lower() + rm_col,\n",
    "                                         'rstd': test_item.replace(' ', '_').lower() + rs_col}, inplace=True)\n",
    "            labs_sel_test = labs_sel_test.drop(['SpecimenCollectionDate', 'SpecimenCollectionTime',\n",
    "                                                'TestItem', 'RangeMin', 'RangeMax'], axis=1)\n",
    "            cur_coh = pd.merge(cur_coh, labs_sel_test, on=['ppid', 'HOSP_adt'], how='left')\n",
    "            \n",
    "        full_coh = pd.concat([full_coh, cur_coh], axis=0)\n",
    "        full_coh[list(col for col in full_coh.columns if 'days' in col)] = full_coh[list(col for col in full_coh.columns if 'days' in col)].fillna(9999).astype(np.int32)\n",
    "        full_coh[list(col for col in full_coh.columns if 'value' in col)] = full_coh[list(col for col in full_coh.columns if 'value' in col)].fillna(-9999.0).astype(np.float32)\n",
    "        full_coh[list(col for col in full_coh.columns if 'rmean' in col)] = full_coh[list(col for col in full_coh.columns if 'rmean' in col)].fillna(-9999.0).astype(np.float32)\n",
    "        full_coh[list(col for col in full_coh.columns if 'rstd' in col)] = full_coh[list(col for col in full_coh.columns if 'rstd' in col)].fillna(-9999.0).astype(np.float32)\n",
    "        full_coh[list(col for col in full_coh.columns if 'normal' in col)] = full_coh[list(col for col in full_coh.columns if 'normal' in col)].fillna(0).astype(np.int8)\n",
    "        full_coh[list(col for col in full_coh.columns if 'recorded' in col)] = full_coh[list(col for col in full_coh.columns if 'recorded' in col)].fillna(0).astype(np.int8)\n",
    "        return full_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17df99-aab7-4f09-93a4-25f458a094c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labs_sel = prep_labs(labs_data, inp_ch)\n",
    "inp_ch = get_lab_features(labs_sel, inp_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480347e-6510-4f95-8fdc-3880a55ec8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape, inp_ch.ppid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f1923a-e70c-4f86-8cba-35abe7f63add",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9158eefa-22b8-45c7-a7c6-9d82bf7bd6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Process chunk 2\n",
    "c_idx = 0\n",
    "term = 1\n",
    "for chunk in pd.read_csv('', sep='\\t', low_memory=False,\n",
    "                        chunksize=chunk_size):\n",
    "    print('Processing chunk:', c_idx)\n",
    "    if c_idx == term:\n",
    "        labs_data = chunk\n",
    "        break\n",
    "    c_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d4de42-1a08-4577-8f20-5f0b201a6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correct eGFR\n",
    "labs_data['RangeMin'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMin'].isnull()), '60.0',\n",
    "                                 labs_data['RangeMin'])\n",
    "labs_data['RangeMax'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMax'].isnull()), '150.0',\n",
    "                                 labs_data['RangeMax'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60.0'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='Not Indicated'), '61.0',\n",
    "                                 labs_data['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78627b4f-5e3e-43bf-8f04-66c6b3770a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labs_sel = prep_labs(labs_data, inp_ch)\n",
    "inp_ch = get_lab_features(labs_sel, inp_ch, rec_col='_recorded2', nor_col='_normal_low2', nor_col2='_normal_high2',\n",
    "                          val_col='_value2', day_col='_days2', rm_col='_rmean2', rs_col='_rstd2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ce49c5-3dd8-49a6-9c87-8d748bae6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c59eee-8685-4e84-8092-5b4216d86a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Process chunk 3\n",
    "c_idx = 0\n",
    "term = 2\n",
    "for chunk in pd.read_csv('', sep='\\t', low_memory=False,\n",
    "                        chunksize=chunk_size):\n",
    "    print('Processing chunk:', c_idx)\n",
    "    if c_idx == term:\n",
    "        labs_data = chunk\n",
    "        break\n",
    "    c_idx += 1\n",
    "## Correct eGFR\n",
    "labs_data['RangeMin'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMin'].isnull()), '60.0',\n",
    "                                 labs_data['RangeMin'])\n",
    "labs_data['RangeMax'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMax'].isnull()), '150.0',\n",
    "                                 labs_data['RangeMax'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60.0'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='Not Indicated'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_sel = prep_labs(labs_data, inp_ch)\n",
    "inp_ch = get_lab_features(labs_sel, inp_ch, rec_col='_recorded3', nor_col='_normal_low3', nor_col2='_normal_high3', val_col='_value3',\n",
    "                         day_col='_days3', rm_col='_rmean3', rs_col='_rstd3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5e3bef-13c0-437b-9faf-9d337c22a907",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2ef1dc-b8e5-4d89-a2b1-4060c56df0fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Process chunk 4\n",
    "#labs_data = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "c_idx = 0\n",
    "term = 3\n",
    "for chunk in pd.read_csv('', sep='\\t', low_memory=False,\n",
    "                        chunksize=chunk_size):\n",
    "    print('Processing chunk:', c_idx)\n",
    "    if c_idx == term:\n",
    "        labs_data = chunk\n",
    "        break\n",
    "    c_idx += 1\n",
    "## Correct eGFR\n",
    "labs_data['RangeMin'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMin'].isnull()), '60.0',\n",
    "                                 labs_data['RangeMin'])\n",
    "labs_data['RangeMax'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['RangeMax'].isnull()), '150.0',\n",
    "                                 labs_data['RangeMax'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='>60.0'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_data['Value'] = np.where((labs_data['TestItem'] == 'eGFR (/1.73m2)')&(labs_data['Value']=='Not Indicated'), '61.0',\n",
    "                                 labs_data['Value'])\n",
    "labs_sel = prep_labs(labs_data, inp_ch)\n",
    "inp_ch = get_lab_features(labs_sel, inp_ch, rec_col='_recorded4', nor_col='_normal_low4', nor_col2='_normal_high4', val_col='_value4',\n",
    "                         day_col='_days4', rm_col='_rmean4', rs_col='_rstd4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e3a52-9120-41dc-b0d2-0b52a7734f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc49eaa-406a-4d3c-b3e6-4c13009651c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff12602f-7cd4-4f6a-ac05-7ee9fb629bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b4551-1cf9-42a2-8b42-ae259e2f01c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge lab test chunk values\n",
    "bloods_names = [col.rsplit('_', 1)[0] for col in inp_ch.columns if '_recorded' in col]\n",
    "bloods_names = list(set(bloods_names))\n",
    "#print(bloods_names, len(bloods_names))\n",
    "blood_columns_r = {bl_name: [col for col in inp_ch.columns if f\"{bl_name}_recorded\" in col] for bl_name in bloods_names}\n",
    "blood_columns_d = {bl_name: [col for col in inp_ch.columns if f\"{bl_name}_days\" in col] for bl_name in bloods_names}\n",
    "blood_columns_v = {bl_name: [col for col in inp_ch.columns if f\"{bl_name}_value\" in col] for bl_name in bloods_names}\n",
    "blood_columns_n1 = {bl_name: [col for col in inp_ch.columns if f\"{bl_name}_normal_low\" in col] for bl_name in bloods_names}\n",
    "blood_columns_n2 = {bl_name: [col for col in inp_ch.columns if f\"{bl_name}_normal_high\" in col] for bl_name in bloods_names}\n",
    "blood_columns_rm = {bl_name: [col for col in inp_ch.columns if f\"{bl_name}_rmean\" in col] for bl_name in bloods_names}\n",
    "blood_columns_rstd = {bl_name: [col for col in inp_ch.columns if f\"{bl_name}_rstd\" in col] for bl_name in bloods_names}\n",
    "\n",
    "def merge_labs_n(b_data, cols):\n",
    "    return np.nanmax(b_data[cols].values, axis=1)\n",
    "    \n",
    "#def merge_labs_n(b_data, cols):\n",
    "    #b_sel = b_data[cols].values\n",
    "    #b_sel = np.where(b_sel!=0, b_sel, np.nan)\n",
    "    #return np.nan_to_num(np.nanmax(b_sel, axis=1), nan=0)\n",
    "           \n",
    "for bl_name in tqdm(bloods_names):\n",
    "    print('Processing ', bl_name)\n",
    "    col_r = blood_columns_r[bl_name]\n",
    "    col_d = blood_columns_d[bl_name]\n",
    "    col_v = blood_columns_v[bl_name]\n",
    "    col_n1 = blood_columns_n1[bl_name]\n",
    "    col_n2 = blood_columns_n2[bl_name]\n",
    "    col_rm = blood_columns_rm[bl_name]\n",
    "    col_rstd = blood_columns_rstd[bl_name]\n",
    "    \n",
    "    if col_r:\n",
    "        inp_ch[bl_name + '_r'] = merge_labs_n(inp_ch, col_r)\n",
    "        print('recorded value')\n",
    "    if col_d:\n",
    "        inp_ch[bl_name + '_d'] = merge_labs_n(inp_ch, col_d)\n",
    "        print('days value')\n",
    "    if col_v:\n",
    "        inp_ch[bl_name + '_v'] = merge_labs_n(inp_ch, col_v)\n",
    "        print('test value')\n",
    "    if col_n1:\n",
    "        inp_ch[bl_name + '_nl'] = merge_labs_n(inp_ch, col_n1)\n",
    "        print('normal low value')\n",
    "    if col_n2:\n",
    "        inp_ch[bl_name + '_nh'] = merge_labs_n(inp_ch, col_n2)\n",
    "        print('normal high value')\n",
    "    if col_rm:\n",
    "        inp_ch[bl_name + '_rm'] = merge_labs_n(inp_ch, col_rm)\n",
    "        print('rolling mean value')\n",
    "    if col_rstd:\n",
    "        inp_ch[bl_name + '_rs'] = merge_labs_n(inp_ch, col_rstd)\n",
    "        print('rolling std value')\n",
    "        \n",
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9de80e-a01c-46aa-9dd7-a4da45eb4f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = inp_ch.drop(inp_ch[[col for col in inp_ch if '_recorded' in col]].columns.tolist(), axis=1)\n",
    "inp_ch = inp_ch.drop(inp_ch[[col for col in inp_ch if '_normal_low' in col]].columns.tolist(), axis=1)\n",
    "inp_ch = inp_ch.drop(inp_ch[[col for col in inp_ch if '_normal_high' in col]].columns.tolist(), axis=1)\n",
    "inp_ch = inp_ch.drop(inp_ch[[col for col in inp_ch if '_value' in col]].columns.tolist(), axis=1)\n",
    "inp_ch = inp_ch.drop(inp_ch[[col for col in inp_ch if '_rstd' in col]].columns.tolist(), axis=1)\n",
    "inp_ch = inp_ch.drop(inp_ch[[col for col in inp_ch if '_rmean' in col]].columns.tolist(), axis=1)\n",
    "inp_ch = inp_ch.drop(inp_ch[[col for col in inp_ch if '_days' in col and not 'vent_days' in col]].columns.tolist(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ca2d9d-3e26-4234-a5e0-4b2a52084cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851eefe2-89ce-454f-af79-23b09787c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inp_ch[list(col for col in inp_ch.columns if '_nl' in col)]:\n",
    "    print(inp_ch.groupby('coh_idx')[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5f537-a47f-46b7-9c02-501c67f99c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='ast:alt_ratio_nl', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='procalcitonin_nl', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='hs_troponin_t_nl', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='ast_nl', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='ast:alt_ratio_nl', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='c-reactive_prot_nl', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='ntprobnp_nl', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='procalcitonin_nh', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='egfr_(/1.73m2)_nh', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='ntprobnp_nh', axis=1).columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8faa5-5583-4fae-851e-108ead836b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8a23ae-bf8a-4264-af19-1cb0379fecc0",
   "metadata": {},
   "source": [
    "#### Prescribing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f19b60-c330-4ad7-8cf1-72b92e71cafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f289ca83-ac2d-4585-95dc-b9d4515836d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chunk 1\n",
    "presc_data = pd.read_csv('', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729e5490-494b-4824-8f57-7e4b0844b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "presc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0822cc0b-2b9b-4f74-815c-098a12e79daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "presc_data['PI BNF Section Description'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bac448b-fc57-4fb9-929c-e0971f095c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pis(presc_data, inp_ch, sample_upper=1000):\n",
    "    PIS_sel = presc_data[['ppid', 'Paid Date', 'PI Approved Name', 'PI BNF Section Description']]\n",
    "    PIS_sel = PIS_sel[PIS_sel.ppid.isin(inp_ch.ppid.unique())]\n",
    "    PIS_sel['Paid Date'] = pd.to_datetime(PIS_sel['Paid Date'])\n",
    "    PIS_sel['PI Approved Name'] = PIS_sel['PI Approved Name'].astype(str).str.strip()\n",
    "    PIS_sel['PI BNF Section Description'] = np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'LIPID-REGULATING DRUGS', 'lipid_regulators',\n",
    "                                                     np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'DIURETICS', 'diuretics',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'HYPERTENSION AND HEART FAILURE', 'anti_hypertension_hf_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'ANTIDEPRESSANT DRUGS', 'antidepressant_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'NITRATES ,CALCIUM-CHANNEL BLOCKERS AND OTHER ANTIANGINAL DRUGS', 'nitrates_ccb_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'BETA-ADRENOCEPTOR BLOCKING DRUGS', 'beta_blockers',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'ANTIPLATELET DRUGS', 'antiplatelet_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'DRUGS AFFECTING BONE METABOLISM', 'bone_metabolism_affecting_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'ANTICOAGULANTS AND PROTAMINE', 'anticoagulant_protamine_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'DRUGS USED IN PSYCHOSES AND RELATED DISORDERS', 'antipsychotics',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'DRUGS FOR DEMENTIA', 'antidementia_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'DRUGS USED IN NAUSEA AND VERTIGO', 'nausea_vertigo_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'DRUGS USED IN PARKINSONISM AND RELATED DISORDERS', 'parkinsonism_drugs',\n",
    "                                                    np.where(PIS_sel['PI BNF Section Description'].str.strip() == 'DRUGS FOR GENITO-URINARY DISORDERS', 'genito_urinary_drugs', 'other'))))))))))))))\n",
    "    PIS_sel = PIS_sel[PIS_sel['PI BNF Section Description'] != 'other']                                 \n",
    "    PIS_sel = PIS_sel.dropna()\n",
    "    print(PIS_sel.shape)\n",
    "    #top_drugs = PIS_sel.groupby('PI Approved Name')['ppid'].count().reset_index(name='count').sort_values('count', ascending=False).head(60)\n",
    "    return PIS_sel\n",
    "\n",
    "def rename(col):\n",
    "    if isinstance(col, tuple):\n",
    "        col = '_'.join(str(c) for c in col)\n",
    "    return col\n",
    "\n",
    "def get_pis_features(pis_sel, inp_ch, n_cohorts=10, window=15):\n",
    "    ### Pipeline\n",
    "    full_coh = pd.DataFrame()\n",
    "    inp_ch['AdmissionDate'] = pd.to_datetime(inp_ch['AdmissionDate'])\n",
    "    for i in range(1, n_cohorts+1, window):\n",
    "        print('Processing cohort:', i)\n",
    "        cur_coh = inp_ch[inp_ch['coh_idx']==i]\n",
    "        pis_ch = pd.merge(pis_sel, cur_coh[['ppid', 'AdmissionDate']], how='left', on='ppid')\n",
    "        pis_ch = pis_ch[((pis_ch['AdmissionDate'] + timedelta(days=0)) > pis_ch['Paid Date'])&(pis_ch.ppid.isin(cur_coh.ppid.unique()))]\n",
    "        ph_drug_ids = pis_ch.groupby(['ppid', 'AdmissionDate', 'PI BNF Section Description']).size().reset_index(name='n_presc')\n",
    "        print(ph_drug_ids.shape)\n",
    "        pis_ch = pis_ch.sort_values(['ppid', 'AdmissionDate', 'Paid Date', 'PI BNF Section Description'])\n",
    "        ph_drug_mind = pis_ch.groupby(['ppid', 'PI BNF Section Description', 'AdmissionDate'])['Paid Date'].min().reset_index(name='first_date')\n",
    "        ph_drug_maxd = pis_ch.groupby(['ppid', 'PI BNF Section Description', 'AdmissionDate'])['Paid Date'].max().reset_index(name='last_date')\n",
    "        ph_drug_mind['dsf'] = ((ph_drug_mind['AdmissionDate'] + timedelta(days=0)) - ph_drug_mind['first_date']).dt.days\n",
    "        ph_drug_maxd['dsl'] = ((ph_drug_maxd['AdmissionDate'] + timedelta(days=0)) - ph_drug_maxd['last_date']).dt.days\n",
    "        ph_drug_ids = pd.merge(ph_drug_ids, ph_drug_mind[['ppid', 'AdmissionDate', 'PI BNF Section Description', 'dsf']], how='left', on=['ppid', 'AdmissionDate', \n",
    "                                                                                                                                          'PI BNF Section Description'])\n",
    "        ph_drug_ids = pd.merge(ph_drug_ids, ph_drug_maxd[['ppid', 'AdmissionDate', 'PI BNF Section Description', 'dsl']], how='left', on=['ppid', 'AdmissionDate', \n",
    "                                                                                                                                          'PI BNF Section Description'])\n",
    "        print(ph_drug_ids.shape)\n",
    "        ph_drug_ids['PI BNF Section Description'] = ph_drug_ids['PI BNF Section Description'].astype(str).replace(' ', '_')\n",
    "        #print(ph_drug_ids.head(10))\n",
    "        ph_drugs_piv = ph_drug_ids.set_index(['ppid', 'AdmissionDate', 'PI BNF Section Description']).unstack()\n",
    "        ph_drugs_piv.columns = map(rename, ph_drugs_piv)\n",
    "        ph_drugs_piv = ph_drugs_piv.reset_index()\n",
    "        ph_drugs_total = ph_drug_ids.groupby(['ppid', 'AdmissionDate'])['PI BNF Section Description'].nunique().reset_index(name='total_drug_categories')\n",
    "        cur_coh = pd.merge(cur_coh, ph_drugs_piv, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, ph_drugs_total, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        full_coh = pd.concat([full_coh, cur_coh], axis=0)\n",
    "\n",
    "    days_cols = list(col for col in full_coh.columns if 'dsf' in col or 'dsl' in col)\n",
    "    nums_cols = list(col for col in full_coh.columns if 'n_presc' in col)\n",
    "    full_coh[days_cols] = full_coh[days_cols].fillna(9999).astype(np.int32)\n",
    "    full_coh[nums_cols] = full_coh[nums_cols].fillna(0).astype(np.int16)\n",
    "    full_coh['total_drug_categories'] = full_coh['total_drug_categories'].fillna(0).astype(np.int8)\n",
    "    return full_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8e4f07-96e8-4378-8b28-1d9d17e5c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "pis_sel = prep_pis(presc_data, inp_ch)\n",
    "inp_ch = get_pis_features(pis_sel, inp_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503bda85-a1bf-44c4-a2da-f45c9f94306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp_ch.columns.tolist()[401:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0619a18-3a78-4594-a315-fe17cfc7ef88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgt_ch = inp_ch.columns[401:]\n",
    "inp_ch = inp_ch.rename(columns={c:c+'_ch1' for c in inp_ch.columns if c in tgt_ch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4482cd-4e05-4445-9bd0-3a2d44edb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chunk 2\n",
    "presc_data = pd.read_csv('', sep='\\t', low_memory=False)\n",
    "pis_sel = prep_pis(presc_data, inp_ch)\n",
    "inp_ch = get_pis_features(pis_sel, inp_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d3abd4-7a1f-4670-8cb1-c53d350e6171",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inp_ch.columns.tolist()[444:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84c044-eb37-4632-a380-4324b60654db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tgt_ch = inp_ch.columns[444:]\n",
    "inp_ch = inp_ch.rename(columns={c:c+'_ch2' for c in inp_ch.columns if c in tgt_ch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6211207-13fc-4c5e-a932-c4a4e505b01f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Merge lab test chunk values\n",
    "dr_names = [\"_\".join(col.split('_')[2:-1]) for col in inp_ch.columns if 'n_presc' in col]\n",
    "dr_names = list(set(dr_names)) + ['total_drug_categories']\n",
    "#print(bloods_names, len(bloods_names))\n",
    "dr_columns_v = {dr_name: [col for col in inp_ch.columns if f\"n_presc_{dr_name}\" in col] for dr_name in dr_names}\n",
    "dr_columns_df = {dr_name: [col for col in inp_ch.columns if f\"dsf_{dr_name}\" in col] for dr_name in dr_names}\n",
    "dr_columns_dl = {dr_name: [col for col in inp_ch.columns if f\"dsl_{dr_name}\" in col] for dr_name in dr_names}\n",
    "dr_columns_c = {'total_drug_categories': ['total_drug_categories_ch1', 'total_drug_categories_ch2']}\n",
    "\n",
    "def merge_dr_v(b_data, cols):\n",
    "    return np.nansum(b_data[cols].values, axis=1)\n",
    "\n",
    "def merge_dr_df(b_data, cols):\n",
    "    return np.nanmax(b_data[cols].values, axis=1)\n",
    "\n",
    "def merge_dr_dl(b_data, cols):\n",
    "    return np.nanmax(b_data[cols].values, axis=1)\n",
    "    \n",
    "def merge_dr_c(b_data, cols):\n",
    "    return np.nanmax(b_data[cols].values, axis=1)\n",
    "           \n",
    "for dr_name in tqdm(dr_names):\n",
    "    print('Processing ', dr_name)\n",
    "    col_v = dr_columns_v[dr_name]\n",
    "    col_df = dr_columns_df[dr_name]\n",
    "    col_dl = dr_columns_dl[dr_name]\n",
    "    if dr_name == 'total_drug_categories':\n",
    "        col_c = dr_columns_c[dr_name]\n",
    "        inp_ch['total_drug_categories'] = merge_labs_n(inp_ch, col_c).astype(np.int8)\n",
    "        print('categories value') \n",
    "    else:\n",
    "        if col_v:\n",
    "            inp_ch['n_presc_' + dr_name] = merge_dr_v(inp_ch, col_v)\n",
    "            print('drug value')\n",
    "        if col_df:\n",
    "            inp_ch['dsf_' + dr_name] = merge_dr_df(inp_ch, col_df)\n",
    "            print('days first value')\n",
    "        if col_dl:\n",
    "            inp_ch['dsl_' + dr_name] = merge_dr_dl(inp_ch, col_dl)\n",
    "            print('days last value')\n",
    "        \n",
    "        \n",
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddcc6d9-8a23-4074-bab0-5b26437977f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inp_ch[list(col for col in inp_ch.columns if 'n_presc' in col)]:\n",
    "    print(inp_ch.groupby('coh_idx')[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db22d27-af02-47c6-bfdc-a86765b3118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = inp_ch.drop([col for col in inp_ch.columns if col.endswith('_ch1') or col.endswith('_ch2')], axis=1)\n",
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40612b-2476-4bc6-ac59-bb3e11813ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape, inp_ch.ppid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a31a2c-7047-4b35-a259-c6e19046e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a2480-d802-4d62-9859-21e5f25f574a",
   "metadata": {},
   "source": [
    "#### GP/SMR READ phenotype history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b001494-f72e-4955-85e4-ce87ba57769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50d818d-acad-441c-a54d-430fc8a28b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr_data = pd.read_csv('', sep='\\t', low_memory=False, encoding='iso-8859-1')\n",
    "gp_data = pd.read_csv('', sep='\\t', low_memory=False, encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0b96c-5bd2-4c4d-ae16-517f49bf0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr_data.PhenotypeGroup.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d416c0-62b6-432e-9af5-e9d4e1a7631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gp_data[gp_data.PhenotypeGroup.str.lower().str.contains('genit')]['PhenotypeName'].value_counts())\n",
    "print(len(smr_data[smr_data.PhenotypeName.str.lower().str.contains('arth')]['PhenotypeName'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b17974-c625-495c-917c-6bab9595a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_pheno_features(cm_data, inp_ch, max_events=1, fn='', ctype='ReadCode'):\n",
    "    READ_sel = cm_data[['ppid', 'EventDate', ctype, 'PhenotypeName', 'PhenotypeCategory', 'PhenotypeGroup']]\n",
    "    READ_sel = READ_sel[READ_sel.ppid.isin(inp_ch.ppid.unique())]\n",
    "    READ_sel['EventDate'] = pd.to_datetime(pd.to_datetime(READ_sel['EventDate']).dt.date)\n",
    "    READ_sel[ctype] = READ_sel[ctype].astype(str).str.strip()\n",
    "    READ_sel['PhenotypeName'] = READ_sel['PhenotypeName'].astype(str).str.strip()\n",
    "    READ_sel = READ_sel.dropna()\n",
    "    print(READ_sel.shape)\n",
    "    READ_types = READ_sel[['ppid', 'PhenotypeName']].groupby(['PhenotypeName']).size().reset_index(name='num_events')\n",
    "    READ_types = READ_types[READ_types['num_events'] > max_events].sort_values('num_events', ascending=False)\n",
    "    to_repl = [' ', '.', ':', '(', ')']\n",
    "    for rep in to_repl:\n",
    "        READ_types['ph_code'] = READ_types['PhenotypeName'].str.replace(rep, ' ')\n",
    "    READ_types['ph_code'] = READ_types['ph_code'].replace(' ', '_', regex=True).str.lower()\n",
    "    READ_types['ph_code'] = READ_types['ph_code'].str.replace('\\W', '_', regex=True).str.replace('__', '_', regex=True).str.rstrip('_')\n",
    "    print(READ_sel.shape)\n",
    "    print(READ_types.shape)\n",
    "    READ_sel = READ_sel[READ_sel['PhenotypeName'].isin(READ_types['PhenotypeName'].unique())]\n",
    "    READ_sel = pd.merge(READ_sel, READ_types[['PhenotypeName', 'ph_code']], how='left', on='PhenotypeName')\n",
    "    READ_sel.drop(columns=[ctype], axis=1, inplace=True)\n",
    "    ### Build custom comorbidity fields as input features\n",
    "    READ_sel['ph_code'] = np.where((READ_sel['PhenotypeName'].str.lower().str.contains('primary malignancy'))|\n",
    "                                        (READ_sel['PhenotypeName'].str.lower().str.contains('secondary malignancy'))|\n",
    "                                        READ_sel['PhenotypeName'].str.contains('|'.join(['Leukaemia', 'Hodgkin Lymphoma', \n",
    "                                                                           'Multiple myeloma and malignant plasma cell neoplasms',\n",
    "                                                                           'Myelodysplastic syndromes', 'Non-Hodgkin Lymphoma'])), \n",
    "                                   'physltc_historical_or_active_cancer', READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Abdominal aortic aneurysm', 'physltc_abd_aortic_aneurysm', READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].str.contains('|'.join(['Coronary heart disease not otherwise specified',\n",
    "                                                                                                              'Myocardial infarction', \n",
    "                                                                                                              'Stable angina',\n",
    "                                                                                                              'Unstable Angina'])), \n",
    "                                   'physltc_ischaemic_heart_disease', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Hypertension']), 'physltc_hypertension', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].str.contains('|'.join(['Ischaemic stroke', 'Stroke NOS',\n",
    "                                                                                            'Intracerebral haemorrhage', \n",
    "                                                                                    'Subarachnoid haemorrhage',\n",
    "                                                                                    'Transient ischaemic attack'])), 'physltc_stroke', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Peripheral arterial disease', 'physltc_per_vascular_disease', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Crohn\\'s disease', 'Ulcerative colitis']), 'physltc_inf_bowel_disease', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Liver fibrosis, sclerosis and cirrhosis',\n",
    "                                                                  'Hepatic failure', 'Oesophageal varices', 'Portal hypertension']), \n",
    "                                   'physltc_liver_disease', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Diabetes', 'Diabetic ophthalmic complications',\n",
    "                                                                  'Diabetic neurological complications']), 'physltc_diabetes', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['End stage renal disease', 'Glomerulonephritis']), 'physltc_chronic_renal_disease', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Osteoarthritis (excl spine)', 'Rheumatoid Arthritis',\n",
    "                                                                  'Psoriatic arthropathy', 'Juvenile arthritis',\n",
    "                                                                  'Enteropathic arthropathy','Ankylosing spondylitis',\n",
    "                                                                  'Spondylolisthesis']), 'physltc_arthritis_arthropathy', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Fracture of hip', 'physltc_hip_fracture', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Dementia', 'Parkinson\\'s disease',\n",
    "                                                                  'Motor neuron disease']), 'physltc_prog_neur_disease', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Chronic Obstructive Pulmonary Disease (COPD)', 'physltc_copd', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Other interstitial pulmonary diseases with fibrosis', \n",
    "                                   'physltc_pulmonary_fibrosis', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Asthma', \n",
    "                                   'physltc_asthma', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Bronchiectasis', \n",
    "                                   'physltc_bronchiectasis', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Epilepsy', \n",
    "                                   'physltc_epilepsy', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Osteoporosis', \n",
    "                                   'physltc_osteoporosis', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Obesity', \n",
    "                                   'physltc_obesity', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Heart failure', \n",
    "                                   'physltc_heart_failure', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Atrial fibrillation', \n",
    "                                   'physltc_atrial_fibrillation', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Alcohol Problems', 'Other psychoactive substance misuse', \n",
    "                                                                  'Alcoholic liver disease']), \n",
    "                                   'menltc_alcohol_substance_misuse', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName'].isin(['Schizophrenia, schizotypal and delusional disorders', \n",
    "                                                                   'Bipolar affective disorder and mania',\n",
    "                                                                  'Autism and Asperger\\'s syndrome',\n",
    "                                                                  'Anorexia and bulimia nervosa']), \n",
    "                                   'menltc_chronic_psychiatry_disorder', \n",
    "                                   READ_sel['ph_code'])\n",
    "    READ_sel['ph_code'] = np.where(READ_sel['PhenotypeName']=='Depression', \n",
    "                                   'menltc_depression', \n",
    "                                   READ_sel['ph_code'])\n",
    "    print(READ_sel.shape)\n",
    "    READ_types = pd.merge(READ_types, READ_sel[['PhenotypeName', 'ph_code']].rename(columns={'ph_code':\n",
    "                                                                                             'ltc_code'}), how='left', on='PhenotypeName').drop_duplicates()\n",
    "    READ_types.to_csv(fn, index=False)\n",
    "    return READ_sel\n",
    "\n",
    "def get_pheno_features(cm_data, inp_ch, n_cohorts=10, window=15, tn='total_GP_cmr',\n",
    "                       dfn='dsf_GP_diag', dln='dsl_GP_diag', gn='GP_diag'):\n",
    "    ### Pipeline\n",
    "    full_coh = pd.DataFrame()\n",
    "    inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'])\n",
    "    inp_ch['AdmissionDate'] = pd.to_datetime(inp_ch['AdmissionDate'])\n",
    "    for i in range(1, n_cohorts+1, window):\n",
    "        print('Processing cohort:', i)\n",
    "        cur_coh = inp_ch[inp_ch['coh_idx']==i]\n",
    "        cm_ch = pd.merge(cm_data, cur_coh[['ppid', 'AdmissionDate']], how='left', on='ppid')\n",
    "        cm_ch = cm_ch[((cm_ch['AdmissionDate'] + timedelta(days=0)) > cm_ch['EventDate'])&(cm_ch.ppid.isin(cur_coh.ppid.unique()))]\n",
    "        READ_sum = cm_ch.groupby(['ppid', 'AdmissionDate']).size().reset_index(name=tn)\n",
    "        #print(cm_ch.head())\n",
    "        READ_ids = cm_ch.groupby(['ppid', 'AdmissionDate', 'ph_code']).size().reset_index(name=tn)\n",
    "        READ_mind = cm_ch.groupby(['ppid', 'ph_code', 'AdmissionDate'])['EventDate'].min().reset_index(name='first_date')\n",
    "        READ_maxd = cm_ch.groupby(['ppid', 'ph_code', 'AdmissionDate'])['EventDate'].max().reset_index(name='last_date')\n",
    "        READ_mind[dfn] = ((READ_mind['AdmissionDate'] + timedelta(days=0)) - pd.to_datetime(READ_mind['first_date'])).dt.days\n",
    "        READ_maxd[dln] = ((READ_maxd['AdmissionDate'] + timedelta(days=0)) - pd.to_datetime(READ_maxd['last_date'])).dt.days\n",
    "        READ_ids = pd.merge(READ_ids, READ_mind[['ppid', 'AdmissionDate', 'ph_code', dfn]], how='left', on=['ppid', 'AdmissionDate', 'ph_code'])\n",
    "        READ_ids = pd.merge(READ_ids, READ_maxd[['ppid', 'AdmissionDate', 'ph_code', dln]], how='left', on=['ppid', 'AdmissionDate', 'ph_code'])\n",
    "        READ_piv = READ_ids.set_index(['ppid', 'AdmissionDate', 'ph_code']).unstack()\n",
    "        READ_piv.columns = map(rename, READ_piv)\n",
    "        READ_piv = READ_piv.reset_index()\n",
    "        READ_total = READ_ids.groupby(['ppid', 'AdmissionDate'])['ph_code'].nunique().reset_index(name=gn)\n",
    "        cur_coh = pd.merge(cur_coh, READ_sum, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, READ_piv, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        full_coh = pd.concat([full_coh, cur_coh], axis=0)\n",
    "\n",
    "    return full_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53c0ef-a0cb-4c9c-b42e-f20f051d2062",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_sel = prep_pheno_features(gp_data, inp_ch)\n",
    "inp_ch = get_pheno_features(gp_sel, inp_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccad63-7618-449a-993d-fe31521f4e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e7fdd5-1efd-49a0-a86f-a2387b4b57a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in inp_ch[list(col for col in inp_ch.columns if 'total_GP_cmr' in col)]:\n",
    "    print(inp_ch.groupby('coh_idx')[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b3d5c9-af0a-4385-9f29-51e4f3ecb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr_sel = prep_pheno_features(smr_data, inp_ch, max_events=1, fn='', ctype='Code')\n",
    "inp_ch = get_pheno_features(smr_sel, inp_ch, tn='total_SMR_cmr',\n",
    "                      dfn='dsf_SMR_diag', dln='dsl_SMR_diag', gn='SMR_diag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c58e81-9b67-420a-b638-034020eb1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inp_ch[list(col for col in inp_ch.columns if 'dsl_SMR_diag' in col)]:\n",
    "    print(inp_ch.groupby('coh_idx')[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87b33e-a2a4-4c0f-87fc-cf4a5d62f363",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95feb73b-eff1-4662-822d-eb1da28a5d83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Combine GP and SMR summary data\n",
    "read_cond = pd.read_csv('')\n",
    "smr_cond = pd.read_csv('')\n",
    "int_cond = list(set(read_cond['ltc_code']) & set(smr_cond['ltc_code']))\n",
    "all_cond = list(set(read_cond['ltc_code']) | set(smr_cond['ltc_code']))\n",
    "for cond in int_cond:\n",
    "    inp_ch['dsf_'+cond] = inp_ch[['dsf_SMR_diag_' + cond, 'dsf_GP_diag_' + cond]].max(axis=1)\n",
    "    inp_ch['dsl_'+cond] = inp_ch[['dsl_SMR_diag_' + cond, 'dsl_GP_diag_' + cond]].min(axis=1)\n",
    "\n",
    "for cond in all_cond:\n",
    "    if (('total_GP_cmr_' + cond) in inp_ch.columns) and (('total_SMR_cmr_' + cond) in inp_ch.columns):\n",
    "        inp_ch['prev_diag_'+cond] = np.where((inp_ch['total_GP_cmr_'+cond]>0)|(inp_ch['total_SMR_cmr_'+cond]>0), 1, 0)\n",
    "        inp_ch['num_diag_'+cond] = inp_ch[['total_GP_cmr_'+cond,'total_SMR_cmr_'+cond]].sum(axis=1).fillna(0).astype(np.int16)\n",
    "    elif (('total_GP_cmr_' + cond) not in inp_ch.columns) and (('total_SMR_cmr_' + cond) in inp_ch.columns):\n",
    "        inp_ch['prev_diag_'+cond] = np.where(inp_ch['total_SMR_cmr_'+cond]>0, 1, 0)\n",
    "        inp_ch['num_diag_'+cond] = inp_ch['total_SMR_cmr_'+cond].fillna(0).astype(np.int16)\n",
    "    elif (('total_GP_cmr_' + cond) in inp_ch.columns) and (('total_SMR_cmr_' + cond) not in inp_ch.columns):\n",
    "        inp_ch['prev_diag_'+cond] = np.where(inp_ch['total_GP_cmr_'+cond]>0, 1, 0)\n",
    "        inp_ch['num_diag_'+cond] = inp_ch['total_GP_cmr_'+cond].fillna(0).astype(np.int16)\n",
    "\n",
    "inp_ch['total_unique_conditions'] = inp_ch[['prev_diag_' + cond for cond in all_cond]].sum(axis=1).astype(np.int16)\n",
    "inp_ch['total_longterm_conditions'] = inp_ch[[col for col in inp_ch if 'prev_diag_physltc' in col or 'prev_diag_menltc' in col]].sum(axis=1).astype(np.int8)\n",
    "inp_ch['total_physlongterm_conditions'] = inp_ch[[col for col in inp_ch if 'prev_diag_physltc' in col]].sum(axis=1).astype(np.int8)\n",
    "inp_ch['total_menlongterm_conditions'] = inp_ch[[col for col in inp_ch if 'prev_diag_menltc' in col]].sum(axis=1).astype(np.int8)\n",
    "inp_ch['phys_men_multimorbidity'] = np.where((inp_ch['total_physlongterm_conditions'] >= 1)&(inp_ch['total_menlongterm_conditions'] >= 1), 1, 0).astype(np.int8)\n",
    "inp_ch = inp_ch.drop(inp_ch.filter(\n",
    "    regex='dsf_SMR_diag|dsl_SMR_diag|total_SMR_cmr|dsf_GP_diag|dsl_GP_diag|total_GP_cmr|num_diag').columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3076991a-6da9-4573-b2e3-9c7490667dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fa665d-dd09-4a71-bd75-c72231e7ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape, inp_ch.ppid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec9dbe8-8867-4d05-80a8-c0deecf14b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.phys_men_multimorbidity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9b69d-2f36-4186-94fa-17da66d36997",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687059e8-a84d-4d3d-ab74-6485d0daf5c7",
   "metadata": {},
   "source": [
    "#### SMR00 outpatient attendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5dbcc-55a4-4248-9305-2c3f2eb58b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr00_data = pd.read_csv('', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbed6f1-4e52-442f-a5a2-57e7d20fa081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outp_features(outp_data, inp_ch, n_cohorts=10, window=15, max_att=1000):\n",
    "    SMR_sel = outp_data[['ppid', 'CLINIC_DATE', 'SPECIALTY', 'CLINIC_ATTENDANCE']]\n",
    "    SMR_sel = SMR_sel[SMR_sel.ppid.isin(inp_ch.ppid.unique())]\n",
    "    SMR_sel['CLINIC_DATE'] = pd.to_datetime(SMR_sel['CLINIC_DATE'])\n",
    "    SMR_sel = SMR_sel.dropna()\n",
    "    smr_specs = SMR_sel.groupby('SPECIALTY').size().reset_index(name='num_specs')\n",
    "    smr_specs = smr_specs['SPECIALTY'].loc[smr_specs['num_specs'] > max_att]\n",
    "    \n",
    "    ### Pipeline\n",
    "    full_coh = pd.DataFrame()\n",
    "    inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'])\n",
    "    inp_ch['AdmissionDate'] = pd.to_datetime(inp_ch['AdmissionDate'])\n",
    "    for i in range(1, n_cohorts+1, window):\n",
    "        print('Processing cohort:', i)\n",
    "        cur_coh = inp_ch[inp_ch['coh_idx']==i]\n",
    "        smr_ch = pd.merge(SMR_sel, cur_coh[['ppid', 'AdmissionDate']], how='left', on='ppid')\n",
    "        smr_ch = smr_ch[((smr_ch['AdmissionDate'] + timedelta(days=0)) > smr_ch['CLINIC_DATE'])&(smr_ch.ppid.isin(cur_coh.ppid.unique()))]\n",
    "        SMR_sum = smr_ch.groupby(['ppid', 'AdmissionDate']).size().reset_index(name='num_outp_attendances')\n",
    "        SMR_min = smr_ch.groupby(['ppid', 'AdmissionDate'])['CLINIC_DATE'].min().reset_index()\n",
    "        SMR_max = smr_ch.groupby(['ppid', 'AdmissionDate'])['CLINIC_DATE'].max().reset_index()\n",
    "        SMR_min['dsf_outp_att'] = ((SMR_min['AdmissionDate'] + timedelta(days=0)) - SMR_min['CLINIC_DATE']).dt.days\n",
    "        SMR_max['dsl_outp_att'] = ((SMR_max['AdmissionDate'] + timedelta(days=0)) - SMR_max['CLINIC_DATE']).dt.days\n",
    "        SMR_sum = pd.merge(SMR_sum, SMR_min[['ppid', 'AdmissionDate', 'dsf_outp_att']], how='left', on=['ppid', 'AdmissionDate'])\n",
    "        SMR_sum = pd.merge(SMR_sum, SMR_max[['ppid', 'AdmissionDate', 'dsl_outp_att']], how='left', on=['ppid', 'AdmissionDate'])\n",
    "        smr_spec_each = smr_ch[['ppid', 'AdmissionDate', 'SPECIALTY']]\n",
    "        smr_spec_each['SPECIALTY'] = np.where(smr_spec_each['SPECIALTY'].isin(list(smr_specs)), smr_spec_each['SPECIALTY'], 'Other')\n",
    "        smr_spec_each = smr_spec_each.groupby(['ppid', 'AdmissionDate', 'SPECIALTY']).size().reset_index(name='num_outp_att')\n",
    "        smr_spec_each = smr_spec_each.pivot_table(index='ppid', columns='SPECIALTY', values='num_outp_att', aggfunc='sum', fill_value=0,\n",
    "                                                  dropna=False)\n",
    "        smr_spec_each.columns = ['num_outp_att_' + str(col).strip() for col in smr_spec_each.columns]\n",
    "        smr_spec_each.reset_index(inplace=True)\n",
    "        smr_spec_each = smr_spec_each.rename(columns={'index':'ppid'})\n",
    "        smr_dna_spec = smr_ch[['ppid', 'AdmissionDate', 'SPECIALTY', 'CLINIC_ATTENDANCE']]\n",
    "        smr_dna_spec['SPECIALTY'] = np.where(smr_dna_spec['SPECIALTY'].isin(list(smr_specs)), smr_dna_spec['SPECIALTY'], 'Other')\n",
    "        smr_dna_spec = smr_dna_spec.loc[smr_dna_spec['CLINIC_ATTENDANCE'] == 8]\n",
    "        smr_dna_spec = smr_dna_spec.groupby(['ppid', 'AdmissionDate', 'SPECIALTY']).size().reset_index(name='num_outp_att_dna')\n",
    "        smr_dna_spec = smr_dna_spec.pivot_table(index='ppid', columns='SPECIALTY', values='num_outp_att_dna', aggfunc='sum', fill_value=0,\n",
    "                                                  dropna=False)\n",
    "        smr_dna_spec.columns = ['num_outp_att_dna_' + str(col).strip() for col in smr_dna_spec.columns]\n",
    "        smr_dna_spec.reset_index(inplace=True)\n",
    "        smr_dna_spec = smr_dna_spec.rename(columns={'index':'ppid'})\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, smr_spec_each, how='left', on=['ppid'])\n",
    "        cur_coh = pd.merge(cur_coh, smr_dna_spec, how='left', on=['ppid'])\n",
    "        full_coh = pd.concat([full_coh, cur_coh], axis=0)\n",
    "\n",
    "    return full_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc31a61-eae2-4c95-80bf-23dcdd9f3c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = get_outp_features(smr00_data, inp_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d0729-ac5c-4e53-a9ba-50dc4def1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2d1cfd-aed8-4138-a79a-7e7a3076c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inp_ch[list(col for col in inp_ch.columns if 'num_outp' in col)]:\n",
    "    print(inp_ch.groupby('coh_idx')[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef77b22-ecfa-4168-af57-4e65647cd3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='REDACTED', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='Other', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='other', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='OTHER', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='_NA', axis=1).columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ad0932-9d57-48de-b2e2-7cfa7589c330",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ce7e1-f571-4d82-9bab-08d120f2bc42",
   "metadata": {},
   "source": [
    "#### SMR01 inpatient history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8855c92b-122b-438d-bb6c-00b98fd3bbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr01_data = pd.read_csv('', sep='\\t', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab0b3d5-50d3-4a99-855c-2d7ae24defc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr01_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5af23a-85b9-4ae3-9b5f-17ecfe9e3731",
   "metadata": {},
   "outputs": [],
   "source": [
    "smr01_data['ADMISSION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f3cc0a-4a28-4643-959c-5ac5cb0bc7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_admission_periods(smr_data):\n",
    "    smr_data_tf = smr_data.sort_values(['ppid', 'ADMISSION_DATE', 'DISCHARGE_DATE'])\n",
    "    smr_data_tf = smr_data_tf[['ppid', 'ADMISSION_DATE', 'DISCHARGE_DATE', 'SPECIALTY']]\n",
    "    smr_data_tf['overlap'] = (smr_data_tf.groupby('ppid').apply(lambda x:(x.DISCHARGE_DATE.shift() - x.ADMISSION_DATE) >= timedelta(0))).reset_index(level=0, drop=True)\n",
    "    idx_col = []\n",
    "    ctr = 1\n",
    "    for idx, r in smr_data_tf.iterrows():\n",
    "        if not r.overlap and idx!=0:\n",
    "            ctr+=1\n",
    "        idx_col.append(ctr)\n",
    "    smr_data_tf['idx'] = idx_col\n",
    "    return smr_data_tf\n",
    "\n",
    "def get_inp_features(inp_data, inp_ch, n_cohorts=10, window=15, max_att=1000):\n",
    "    SMR_sel = inp_data[['ppid', 'ADMISSION_DATE', 'DISCHARGE_DATE', 'SPECIALTY', 'ADMISSION_TYPE']]\n",
    "    ## include only unscheduled/urgent admission info\n",
    "    SMR_sel = SMR_sel[SMR_sel['ADMISSION_TYPE']>=20].drop('ADMISSION_TYPE', axis=1)\n",
    "    SMR_sel = SMR_sel[SMR_sel.ppid.isin(inp_ch.ppid.unique())]\n",
    "    SMR_sel['ADMISSION_DATE'] = pd.to_datetime(SMR_sel['ADMISSION_DATE'])\n",
    "    SMR_sel['DISCHARGE_DATE'] = pd.to_datetime(SMR_sel['DISCHARGE_DATE'])\n",
    "    SMR_sel = SMR_sel.dropna()\n",
    "    print(SMR_sel.shape)\n",
    "    SMR_sel = get_admission_periods(SMR_sel)\n",
    "    SMR_start = SMR_sel.groupby(['ppid', 'idx'])['ADMISSION_DATE'].min().reset_index(name='start_date')\n",
    "    SMR_end = SMR_sel.groupby(['ppid', 'idx'])['DISCHARGE_DATE'].max().reset_index(name='end_date')\n",
    "    SMR_sp = SMR_sel.groupby(['ppid', 'idx'])['SPECIALTY'].last().reset_index()\n",
    "    SMR_full = pd.merge(SMR_start, SMR_end, how='left', on=['ppid', 'idx'])\n",
    "    SMR_full = pd.merge(SMR_full, SMR_sp, how='left', on=['ppid', 'idx'])\n",
    "    SMR_full['inp_hospital_days'] = (SMR_full.end_date - SMR_full.start_date).dt.days + 1\n",
    "    SMR_full['stay>7d'] = np.where(SMR_full['inp_hospital_days'] > 7, 1, 0)\n",
    "    SMR_full['stay>14d'] = np.where(SMR_full['inp_hospital_days'] > 14, 1, 0)\n",
    "    SMR_full['stay>21d'] = np.where(SMR_full['inp_hospital_days'] > 21, 1, 0)\n",
    "    smr_specs = SMR_full.groupby('SPECIALTY').size().reset_index(name='num_specs')\n",
    "    smr_specs = smr_specs['SPECIALTY'].loc[smr_specs['num_specs'] > max_att]\n",
    "    ### Pipeline\n",
    "    full_coh = pd.DataFrame()\n",
    "    inp_ch['HOSP_adt'] = pd.to_datetime(inp_ch['HOSP_adt'])\n",
    "    inp_ch['AdmissionDate'] = pd.to_datetime(inp_ch['AdmissionDate'])\n",
    "    for i in range(1, n_cohorts+1, window):\n",
    "        print('Processing cohort:', i)\n",
    "        cur_coh = inp_ch[inp_ch['coh_idx']==i]\n",
    "        smr_ch = pd.merge(SMR_full, cur_coh[['ppid', 'AdmissionDate']], how='left', on='ppid')\n",
    "        smr_ch = smr_ch[((smr_ch['AdmissionDate'] + timedelta(days=0)) > smr_ch['start_date'])&(smr_ch.ppid.isin(cur_coh.ppid.unique()))]\n",
    "        SMR_sum = smr_ch.groupby(['ppid', 'AdmissionDate']).size().reset_index(name='num_inp_attendances')\n",
    "        SMR_sum_days = smr_ch.groupby(['ppid', 'AdmissionDate'])['inp_hospital_days'].sum().reset_index(name='total_inp_hospital_days')\n",
    "        SMR_sum_days_m = smr_ch.groupby(['ppid', 'AdmissionDate'])['inp_hospital_days'].median().reset_index(name='median_inp_hospital_days')\n",
    "        SMR_sum_los1 = smr_ch.groupby(['ppid', 'AdmissionDate'])['stay>7d'].sum().reset_index(name='total_inp_hospital_days>7d')\n",
    "        SMR_sum_los2 = smr_ch.groupby(['ppid', 'AdmissionDate'])['stay>14d'].sum().reset_index(name='total_inp_hospital_days>14d')\n",
    "        SMR_sum_los3 = smr_ch.groupby(['ppid', 'AdmissionDate'])['stay>21d'].sum().reset_index(name='total_inp_hospital_days>21d')\n",
    "        SMR_full_lyr = smr_ch[smr_ch.start_date >= ((smr_ch['AdmissionDate'] + timedelta(days=0)) - pd.DateOffset(days=365))]\n",
    "        SMR_sum_lyr = SMR_full_lyr.groupby(['ppid', 'AdmissionDate']).size().reset_index(name='num_inp_attendances_lyr')\n",
    "        SMR_sum_days_lyr = SMR_full_lyr.groupby(['ppid', 'AdmissionDate'])['inp_hospital_days'].sum().reset_index(name='total_inp_hospital_days_lyr')\n",
    "        SMR_sum_days_m_lyr = SMR_full_lyr.groupby(['ppid', 'AdmissionDate'])['inp_hospital_days'].median().reset_index(name='median_inp_hospital_days_lyr')\n",
    "        SMR_sum_los1_lyr = SMR_full_lyr.groupby(['ppid', 'AdmissionDate'])['stay>7d'].sum().reset_index(name='total_inp_hospital_days>7d_lyr')\n",
    "        SMR_sum_los2_lyr = SMR_full_lyr.groupby(['ppid', 'AdmissionDate'])['stay>14d'].sum().reset_index(name='total_inp_hospital_days>14d_lyr')\n",
    "        SMR_sum_los3_lyr = SMR_full_lyr.groupby(['ppid', 'AdmissionDate'])['stay>21d'].sum().reset_index(name='total_inp_hospital_days>21d_lyr')\n",
    "\n",
    "        SMR_min = smr_ch.groupby(['ppid', 'AdmissionDate'])['start_date'].min().reset_index()\n",
    "        SMR_max = smr_ch.groupby(['ppid', 'AdmissionDate'])['start_date'].max().reset_index()\n",
    "        SMR_min['dsf_inp_att'] = ((SMR_min['AdmissionDate'] + timedelta(days=0)) - SMR_min['start_date']).dt.days\n",
    "        SMR_max['dsl_inp_att'] = ((SMR_max['AdmissionDate'] + timedelta(days=0)) - SMR_max['start_date']).dt.days\n",
    "        SMR_sum = pd.merge(SMR_sum, SMR_min[['ppid', 'AdmissionDate', 'dsf_inp_att']], how='left', on=['ppid', 'AdmissionDate'])\n",
    "        SMR_sum = pd.merge(SMR_sum, SMR_max[['ppid', 'AdmissionDate', 'dsl_inp_att']], how='left', on=['ppid', 'AdmissionDate'])\n",
    "\n",
    "        smr_spec_each = smr_ch[['ppid', 'AdmissionDate', 'SPECIALTY']]\n",
    "        smr_spec_each['Specialty'] = np.where(smr_spec_each['SPECIALTY'].isin(list(smr_specs)), smr_spec_each['SPECIALTY'], 'Other')\n",
    "        smr_spec_each = smr_spec_each.groupby(['ppid', 'AdmissionDate', 'SPECIALTY']).size().reset_index(name='num_inp_att')\n",
    "        smr_spec_each = smr_spec_each.pivot_table(index='ppid', columns='SPECIALTY', values='num_inp_att', aggfunc='sum', fill_value=0,\n",
    "                                                  dropna=False)\n",
    "        smr_spec_each.columns = ['num_inp_att_' + str(col).strip() for col in smr_spec_each.columns]\n",
    "        smr_spec_each.reset_index(inplace=True)\n",
    "        smr_spec_each = smr_spec_each.rename(columns={'index':'ppid'})\n",
    "        \n",
    "        \n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_days, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_days_m, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_los1, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_los2, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_los3, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_lyr, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_days_lyr, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_days_m_lyr, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_los1_lyr, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_los2_lyr, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, SMR_sum_los3_lyr, how='left', on=['ppid', 'AdmissionDate'])\n",
    "        cur_coh = pd.merge(cur_coh, smr_spec_each, how='left', on=['ppid'])\n",
    "    \n",
    "        full_coh = pd.concat([full_coh, cur_coh], axis=0)\n",
    "\n",
    "    return full_coh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ad8651-f414-422c-a6f1-f38c01a4c7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = get_inp_features(smr01_data, inp_ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bb7b81-8c24-400e-b751-5f534cfd9a9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in inp_ch[list(col for col in inp_ch.columns if 'num_inp_att' in col)]:\n",
    "    print(inp_ch.groupby('coh_idx')[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41858d4e-6c99-42a9-a082-6cadfdd88413",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091fa053-787f-4521-87d6-805669730416",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='num_inp_att_A81', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='num_inp_att_H1', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='num_inp_att_CC', axis=1).columns, axis=1)\n",
    "inp_ch = inp_ch.drop(columns=inp_ch.filter(like='inp_hospital_days', axis=1).columns, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87818666-52d2-436f-aaaf-faedd3c6b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch[[col for col in inp_ch.columns if col.endswith('_d')]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30690db2-50ad-47d0-a185-a7828a8a9b44",
   "metadata": {},
   "source": [
    "#### Deal with NAs and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e41cd5-6ac5-4701-9cbc-9620d156d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch[list(col for col in inp_ch.columns if 'num_inp' in col)] = inp_ch[list(col for col in inp_ch.columns if 'num_inp' in col)].fillna(0).astype(np.int16)\n",
    "inp_ch[list(col for col in inp_ch.columns if 'num_outp' in col)] = inp_ch[list(col for col in inp_ch.columns if 'num_outp' in col)].fillna(0).astype(np.int16)\n",
    "inp_ch[list(col for col in inp_ch.columns if 'dsf' in col)] = inp_ch[list(col for col in inp_ch.columns if 'dsf' in col)].fillna(39999).astype(np.int32)\n",
    "inp_ch[list(col for col in inp_ch.columns if 'dsl' in col)] = inp_ch[list(col for col in inp_ch.columns if 'dsl' in col)].fillna(39999).astype(np.int32)\n",
    "inp_ch[[col for col in inp_ch.columns if col.endswith('_d')]] = inp_ch[[col for col in inp_ch.columns if col.endswith('_d')]].fillna(39999).astype(np.int32)\n",
    "inp_ch[[col for col in inp_ch.columns if col.endswith('_d')]] = np.where(inp_ch[[col for col in inp_ch.columns if col.endswith('_d')]]==-9999.0, 39999, inp_ch[[col for col in inp_ch.columns if col.endswith('_d')]])\n",
    "inp_ch[list(col for col in inp_ch.columns if 'total_inp_' in col)] = inp_ch[list(col for col in inp_ch.columns if 'total_inp_' in col)].fillna(0).astype(np.int32)\n",
    "inp_ch[list(col for col in inp_ch.columns if 'median_inp_' in col)] = inp_ch[list(col for col in inp_ch.columns if 'median_inp_' in col)].fillna(0.0).astype(np.float32)\n",
    "inp_ch[list(col for col in inp_ch.columns if 'prev_diag_' in col)] = inp_ch[list(col for col in inp_ch.columns if 'prev_diag_' in col)].fillna(0).astype(np.int8)\n",
    "inp_ch[list(col for col in inp_ch.columns if 'total_unique_conditions' in col)] = inp_ch[list(col for col in inp_ch.columns if 'total_unique_conditions' in col)].fillna(0).astype(np.int8)\n",
    "inp_ch[list(col for col in inp_ch.columns if col.endswith('_rm'))] = inp_ch[list(col for col in inp_ch.columns if col.endswith('_rm'))].round(2).astype(np.float32)\n",
    "inp_ch[list(col for col in inp_ch.columns if col.endswith('_rs'))] = inp_ch[list(col for col in inp_ch.columns if col.endswith('_rs'))].round(2).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a476354-100e-42e5-bdfd-c6602863a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.isnull().any().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003c5c5-dcd0-4a1f-89ad-47d046a31387",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c652082c-99af-46c1-a784-826189b90448",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.shape, inp_ch.ppid.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb9c03-2573-4fc7-9137-6d7435408ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch['AdmissionDate'] = inp_ch['AdmissionDate'].astype('category')\n",
    "inp_ch['HOSP_adt'] = inp_ch['HOSP_adt'].astype('category')\n",
    "inp_ch['DischargeDate'] = inp_ch['DischargeDate'].astype('category')\n",
    "inp_ch['HOSP_ddt'] = inp_ch['HOSP_ddt'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a819a90-0b96-4837-9add-3b2cceb09180",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(inp_ch.dtypes).to_csv('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0a5e11-f81d-44b2-a81e-9461ee64631f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_ch.sort_values(['ppid', 'HOSP_adt']).to_csv('', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
