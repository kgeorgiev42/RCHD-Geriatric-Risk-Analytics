{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7728e1d-2d57-4af5-a3f2-8a83a87769ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "from statistics import mean, median\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from confidenceinterval import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report, confusion_matrix, roc_curve, precision_recall_curve, auc, f1_score, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibrationDisplay, calibration_curve\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from xgboost import cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd509b8-a7cc-4a52-a6d7-eacdeb328ed8",
   "metadata": {},
   "source": [
    "#### Regression K-fold performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aecd69e-8a6b-4e45-8255-8a8125fd419f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lkup_fields = ['ppid',\n",
    " 'EpisodeNumber',\n",
    " 'AdmissionDate',\n",
    " 'ED_adate_dt',\n",
    " 'IndexAttDate',\n",
    " 'HOSP_adt',\n",
    " 'DischargeDate',\n",
    " 'HOSP_ddt',\n",
    " 'breq_dt',\n",
    " 'HOSP_FCC_dt',\n",
    " 'HOSP_FAS_dt',\n",
    " 'gt_m',\n",
    " 'gt_cc',\n",
    " 'gt_es_hosp',\n",
    " 'gt_dd',\n",
    " 'total_count_all',\n",
    " 'total_count_rehab',\n",
    " 'total_count_all_tf',\n",
    " 'total_n_disciplines',\n",
    " 'total_count_ooh_all',\n",
    " 'total_n_disciplines_gr',\n",
    " 'age_gr',\n",
    " 'total_count_cts_gr']\n",
    "\n",
    "#### Load features while specifying data types for memory efficiency\n",
    "dem_types = pd.read_csv('', names=['item', 'dtype'], skiprows=1)\n",
    "dtype_dict = {}\n",
    "for idx, row in dem_types.iterrows():\n",
    "    dtype_dict[row['item']] = row['dtype']\n",
    "\n",
    "base_path = ''\n",
    "model_path = ''\n",
    "train_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True)\n",
    "val_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True, dtype=dtype_dict)\n",
    "\n",
    "train_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in train_data.columns]\n",
    "train_data.columns = [col.replace(',', '_') if ',' in col else col for col in train_data.columns]\n",
    "val_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in val_data.columns]\n",
    "val_data.columns = [col.replace(',', '_') if ',' in col else col for col in val_data.columns]\n",
    "\n",
    "### Shuffle data when using time-series split\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "### Lookup fields\n",
    "train_lkup_cts = train_data[lkup_fields]\n",
    "val_lkup_cts = val_data[lkup_fields]\n",
    "### GT fields\n",
    "train_y = train_data['total_count_all_tf']\n",
    "val_y = val_data['total_count_all_tf']\n",
    "### XGBoost features\n",
    "train_x = train_data.loc[:, ~train_data.columns.isin(lkup_fields)]\n",
    "val_x = val_data.loc[:, ~val_data.columns.isin(lkup_fields)]\n",
    "all_x = pd.concat([train_x, val_x], axis=0)\n",
    "all_y = pd.concat([train_y, val_y], axis=0)\n",
    "print(train_x.columns.tolist())\n",
    "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc2c96a-57f0-49ea-b3d4-041e4cca9cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = 50\n",
    "rounds = 2000\n",
    "\n",
    "params_def = {\n",
    "    'max_depth': 3,\n",
    "    'objective': 'reg:pseudohubererror',\n",
    "    'nthread': 25,\n",
    "    #'eval_metric': 'mape',\n",
    "    'eta': 0.01,\n",
    "    #'colsample_bytree': .5,\n",
    "    #'alpha': 1\n",
    "    #'lambda': 2\n",
    "    ### For imbalanced data\n",
    "    #'scale_pos_weight': pos_weight\n",
    "    #'subsample': .6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f35eed-1044-46f4-9d5a-1bc41f2afd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':12, 'font.weight':'normal', 'font.family':'serif'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0c3ad-21af-4e49-8ef1-aedcc76e8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(labels_true, labels_pred, metric_func, n_iter=1000):\n",
    "    n = len(labels_true)\n",
    "    res = np.zeros(n_iter)\n",
    "    for i in range(n_iter):\n",
    "        ind = np.random.randint(0, n, n)\n",
    "        sample_true = labels_true[ind]\n",
    "        sample_pred = labels_pred[ind]\n",
    "        res[i] = metric_func(sample_true, sample_pred)\n",
    "    return res\n",
    "\n",
    "def compute_ci(bootstrap_res, ci=0.95):\n",
    "    lp = (1 - ci) / 2\n",
    "    up = 1 - lp\n",
    "    return np.round(np.percentile(bootstrap_res, [lp*100, up*100]), 3)\n",
    "\n",
    "def rmse(labels_true, labels_pred):\n",
    "    return np.sqrt(mean_squared_error(labels_true, labels_pred))\n",
    "\n",
    "def mae(labels_true, labels_pred):\n",
    "    return mean_absolute_error(labels_true, labels_pred)\n",
    "\n",
    "def mape(labels_true, labels_pred):\n",
    "    return np.mean(2 * np.abs(labels_true - labels_pred) / (np.abs(labels_true) + np.abs(labels_pred))) * 100\n",
    "\n",
    "def mape_c(labels_true, labels_pred):\n",
    "    mask = labels_true != 0\n",
    "    return np.mean(np.abs((labels_true[mask] - labels_pred[mask]) / labels_true[mask])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf666a50-7143-4dae-af2d-b364b44fe454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_kfold_performance(all_x, all_y, rounds, params_def, folds=10):\n",
    "    \n",
    "    print('Cross-validated regression over 10 folds (care intensity).')\n",
    "    cv = KFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    model=xgb.XGBRegressor(n_estimators=rounds, max_depth=params_def['max_depth'],\n",
    "                            learning_rate=params_def['eta'],\n",
    "                            n_jobs=params_def['nthread'],\n",
    "                            objective=params_def['objective'],\n",
    "                            random_state=42)\n",
    "    rmses = []; maes = []; mapes = [];\n",
    "    for i, (train,test) in tqdm(enumerate(cv.split(all_x,all_y))):\n",
    "        print(f'Evaluating fold {i+1}')\n",
    "        print('-----------------------')\n",
    "        model.fit(all_x.iloc[train], all_y.iloc[train])\n",
    "        labels_val = np.array(all_y.iloc[test].values)\n",
    "        labels_pred_val = model.predict(all_x.iloc[test])\n",
    "        rmse_ci = compute_ci(bootstrap_metric(labels_val, labels_pred_val, rmse))\n",
    "        mae_ci = compute_ci(bootstrap_metric(labels_val, labels_pred_val, mae))\n",
    "        mape_ci = compute_ci(bootstrap_metric(labels_val, labels_pred_val, mape_c))\n",
    "        rmse_val = round(rmse(labels_val, labels_pred_val), 3)\n",
    "        mae_val = round(mae(labels_val, labels_pred_val), 3)\n",
    "        mape_val = round(mape_c(labels_val, labels_pred_val), 3)\n",
    "        print(f'RMSE: {rmse_val}, 95% CI: {rmse_ci}')\n",
    "        print(f'MAE: {mae_val}, 95% CI: {mae_ci}')\n",
    "        print(f'MAPE: {mape_val}, 95% CI: {mape_ci}')\n",
    "        print('-----------------------')\n",
    "        rmses.append(rmse_val)\n",
    "        maes.append(mae_val)\n",
    "        mapes.append(mape_val)\n",
    "\n",
    "    mean_rmse = np.mean(rmses)\n",
    "    mean_mae = np.mean(maes)\n",
    "    mean_mapes = np.mean(mapes)\n",
    "    std_rmse = np.std(rmses)\n",
    "    std_mae = np.std(maes)\n",
    "    std_mape = np.std(mapes)\n",
    "    print('Overall scores')\n",
    "    print(r'Mean RMSE=%0.3f $\\pm$ %0.3f'%(mean_rmse, std_rmse))\n",
    "    print(r'Mean MAE=%0.3f $\\pm$ %0.3f'%(mean_mae, std_mae))\n",
    "    print(r'Mean MAPE=%0.3f $\\pm$ %0.3f'%(mean_mapes, std_mape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29a258-0ad3-4f83-bef4-d991422e7960",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_reg_kfold_performance(all_x, all_y, rounds, params_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9715ba10-4a74-4df3-8bc2-9d671c5db134",
   "metadata": {},
   "source": [
    "#### Validate on in-hospital death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a2376-341b-4062-b21f-c5dd9c0dabe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load features while specifying data types for memory efficiency\n",
    "dem_types = pd.read_csv('', names=['item', 'dtype'], skiprows=1)\n",
    "dtype_dict = {}\n",
    "for idx, row in dem_types.iterrows():\n",
    "    dtype_dict[row['item']] = row['dtype']\n",
    "    \n",
    "lkup_fields = ['ppid',\n",
    " 'EpisodeNumber',\n",
    " 'AdmissionDate',\n",
    " 'ED_adate_dt',\n",
    " 'IndexAttDate',\n",
    " 'HOSP_adt',\n",
    " 'DischargeDate',\n",
    " 'HOSP_ddt',\n",
    " 'breq_dt',\n",
    " 'HOSP_FCC_dt',\n",
    " 'HOSP_FAS_dt',\n",
    " 'gt_m',\n",
    " 'gt_cc',\n",
    " 'gt_es_hosp',\n",
    " 'gt_dd',\n",
    " 'total_count_all',\n",
    " 'total_count_rehab',\n",
    " 'total_count_all_tf',\n",
    " 'total_n_disciplines',\n",
    " 'total_count_ooh_all',\n",
    " 'total_n_disciplines_gr',\n",
    " 'age_gr',\n",
    " 'total_count_cts_gr']\n",
    "\n",
    "base_path = ''\n",
    "model_path = ''\n",
    "train_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True)\n",
    "val_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True, dtype=dtype_dict)\n",
    "\n",
    "train_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in train_data.columns]\n",
    "train_data.columns = [col.replace(',', '_') if ',' in col else col for col in train_data.columns]\n",
    "val_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in val_data.columns]\n",
    "val_data.columns = [col.replace(',', '_') if ',' in col else col for col in val_data.columns]\n",
    "\n",
    "### Shuffle data when using time-series split\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "### Lookup fields\n",
    "train_lkup_m = train_data[lkup_fields]\n",
    "val_lkup_m = val_data[lkup_fields]\n",
    "### GT fields\n",
    "train_y = train_data['gt_m']\n",
    "val_y = val_data['gt_m']\n",
    "### XGBoost features\n",
    "train_x = train_data.loc[:, ~train_data.columns.isin(lkup_fields)]\n",
    "val_x = val_data.loc[:, ~val_data.columns.isin(lkup_fields)]\n",
    "all_x = pd.concat([train_x, val_x], axis=0)\n",
    "all_y = pd.concat([train_y, val_y], axis=0)\n",
    "print(train_x.columns.tolist())\n",
    "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77b977-f2fa-400b-ba5b-c4f761e98934",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = 100\n",
    "rounds = 2000\n",
    "pos_weight = round(len(train_y_m[train_y_m==0]) / len(train_y_m[train_y_m==1]), 3)\n",
    "print('Weight scale parameter for imbalanced data:', pos_weight)\n",
    "print(round(len(train_y_m[train_y_m==1])/ len(train_y_m), 2))\n",
    "params_def = {\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 25,\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': .01,\n",
    "    #'colsample_bytree': .5,\n",
    "    #'alpha': 1\n",
    "    #'lambda': 2\n",
    "    ### For imbalanced data\n",
    "    #'scale_pos_weight': pos_weight\n",
    "    #'subsample': .6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df635956-1ed0-422f-9d2d-c3e80975c066",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':12, 'font.weight':'normal', 'font.family':'serif'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93628c88-b9d6-4aac-933a-e8d0e39c37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_kfold_performance(all_x, all_y, rounds, params_def, early_stopping, folds=10,\n",
    "                              roc_title='Cross-validated ROC Curve over 10 folds (in-hospital death).',\n",
    "                             colors=['#543005', '#8c510a','#bf812d', '#dfc27d', '#f6e8c3',\n",
    "                                    '#c7eae5', '#80cdc1', '#35978f', '#01665e', '#003c30']):\n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    model=xgb.XGBClassifier(n_estimators=rounds, max_depth=params_def['max_depth'],\n",
    "                            learning_rate=params_def['eta'],\n",
    "                            n_jobs=params_def['nthread'], eval_metric=params_def['eval_metric'],\n",
    "                            objective=params_def['objective'],\n",
    "                            random_state=42)\n",
    "    tprs = []; aucs = [];\n",
    "    mean_fpr = np.linspace(0,1,100)\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    lbl_list = []\n",
    "    for i, (train,test) in tqdm(enumerate(cv.split(all_x,all_y))):\n",
    "        model.fit(all_x.iloc[train], all_y.iloc[train])\n",
    "        labels_val = np.array(all_y.iloc[test].values)\n",
    "        #labels_pred_val = model.predict(all_x.iloc[test])\n",
    "        labels_pred_val = model.predict_proba(all_x.iloc[test])[:, 1]\n",
    "        #print(labels_val.shape, labels_pred_val.shape)\n",
    "        #print(labels_val[labels_val==0].shape)\n",
    "        #print(labels_val[labels_val==1].shape)\n",
    "        #print(labels_pred_val)\n",
    "        aucss, ci = roc_auc_score(labels_val, labels_pred_val, confidence_level=0.95)\n",
    "        fpr_val, tpr_val, th_val = roc_curve(labels_val, labels_pred_val, pos_label=1)\n",
    "        label = f'Fold {i+1} (AUC={aucss:.2f}, 95% CI:[{ci[0]:.2f}, {ci[1]:.2f}])'\n",
    "        print(label)\n",
    "        lbl_list.append(label)\n",
    "        RocCurveDisplay(fpr=fpr_val, tpr=tpr_val, roc_auc=aucss, estimator_name=label).plot(ax=ax, color=colors[i])\n",
    "        #viz = RocCurveDisplay.from_estimator(model, all_x.iloc[test], all_y.iloc[test], \n",
    "                                             #estimator-name='Fold {}'.format(i+1), alpha=0.3, lw=1, ax=ax)\n",
    "        interp_tpr = np.interp(mean_fpr, fpr_val, tpr_val)\n",
    "        interp_tpr[0] = 0.0\n",
    "        tprs.append(interp_tpr)\n",
    "        aucs.append(aucss)\n",
    "\n",
    "    ax.plot([0,1], [0,1], color='navy', lw=2, linestyle='--', alpha=0.8)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0\n",
    "    mean_auc = auc(mean_fpr, mean_tpr)\n",
    "    std_auc = np.std(aucs)\n",
    "    ax.plot(mean_fpr, mean_tpr, color='r', label=r'Mean ROC (AUC=%0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc), lw=2, alpha=0.8)\n",
    "    lbl_list.append(r'Mean ROC (AUC=%0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc))\n",
    "    std_tpr = np.std(tprs,axis=0)\n",
    "    tprs_u = np.minimum(mean_tpr + std_tpr, 1)\n",
    "    tprs_l = np.maximum(mean_tpr - std_tpr, 0)\n",
    "    ax.fill_between(mean_fpr, tprs_l, tprs_u, color='grey', alpha=0.5, label=r'$\\pm$ 1 std. dev')\n",
    "    lbl_list.append(r'$\\pm$ 1 std. dev')\n",
    "    ax.set(xlim=[-0.05, 1.05], ylim=[-0.05, 1.05], title=roc_title)\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.legend(loc='lower right', labels=lbl_list)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4c947-14f3-409a-9487-6ec39ebf2661",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_kfold_performance(all_x, all_y, rounds, params_def, early_stopping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b14b5f-93eb-401c-9f32-4e74d7a54ac0",
   "metadata": {},
   "source": [
    "#### Validate on extended stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a3c64-7795-4808-92b6-629ce6f7de1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load features while specifying data types for memory efficiency\n",
    "dem_types = pd.read_csv('', names=['item', 'dtype'], skiprows=1)\n",
    "dtype_dict = {}\n",
    "for idx, row in dem_types.iterrows():\n",
    "    dtype_dict[row['item']] = row['dtype']\n",
    "    \n",
    "lkup_fields = ['ppid',\n",
    " 'EpisodeNumber',\n",
    " 'AdmissionDate',\n",
    " 'ED_adate_dt',\n",
    " 'IndexAttDate',\n",
    " 'HOSP_adt',\n",
    " 'DischargeDate',\n",
    " 'HOSP_ddt',\n",
    " 'breq_dt',\n",
    " 'HOSP_FCC_dt',\n",
    " 'HOSP_FAS_dt',\n",
    " 'gt_m',\n",
    " 'gt_cc',\n",
    " 'gt_es_hosp',\n",
    " 'gt_dd',\n",
    " 'total_count_all',\n",
    " 'total_count_rehab',\n",
    " 'total_count_all_tf',\n",
    " 'total_n_disciplines',\n",
    " 'total_count_ooh_all',\n",
    " 'total_n_disciplines_gr',\n",
    " 'age_gr',\n",
    " 'total_count_cts_gr']\n",
    "\n",
    "base_path = ''\n",
    "model_path = ''\n",
    "train_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True)\n",
    "val_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True, dtype=dtype_dict)\n",
    "\n",
    "train_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in train_data.columns]\n",
    "train_data.columns = [col.replace(',', '_') if ',' in col else col for col in train_data.columns]\n",
    "val_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in val_data.columns]\n",
    "val_data.columns = [col.replace(',', '_') if ',' in col else col for col in val_data.columns]\n",
    "\n",
    "### Shuffle data when using time-series split\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "### Lookup fields\n",
    "train_lkup_m = train_data[lkup_fields]\n",
    "val_lkup_m = val_data[lkup_fields]\n",
    "### GT fields\n",
    "train_y = train_data['gt_es_hosp']\n",
    "val_y = val_data['gt_es_hosp']\n",
    "### XGBoost features\n",
    "train_x = train_data.loc[:, ~train_data.columns.isin(lkup_fields)]\n",
    "val_x = val_data.loc[:, ~val_data.columns.isin(lkup_fields)]\n",
    "all_x = pd.concat([train_x, val_x], axis=0)\n",
    "all_y = pd.concat([train_y, val_y], axis=0)\n",
    "print(train_x.columns.tolist())\n",
    "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb2eb6-1ce7-4d38-a82b-e86fa1195c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = 100\n",
    "rounds = 2000\n",
    "pos_weight = round(len(train_y_m[train_y_m==0]) / len(train_y_m[train_y_m==1]), 3)\n",
    "print('Weight scale parameter for imbalanced data:', pos_weight)\n",
    "print(round(len(train_y_m[train_y_m==1])/ len(train_y_m), 2))\n",
    "params_def = {\n",
    "    'max_depth': 4,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 25,\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': .01,\n",
    "    #'colsample_bytree': .5,\n",
    "    #'alpha': 1\n",
    "    #'lambda': 2\n",
    "    ### For imbalanced data\n",
    "    #'scale_pos_weight': pos_weight\n",
    "    #'subsample': .6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65adaa58-689a-4b31-ad2a-dc61f42fcff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_kfold_performance(all_x, all_y, rounds, params_def, early_stopping,\n",
    "                         roc_title='Cross-validated ROC Curve over 10 folds (extended stay).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe122cf-ed55-484c-8f70-57931b37582c",
   "metadata": {},
   "source": [
    "#### Validate on ICU/HDU admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ddd80f-5553-4f6e-8712-97013a5978b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load features while specifying data types for memory efficiency\n",
    "dem_types = pd.read_csv('', names=['item', 'dtype'], skiprows=1)\n",
    "dtype_dict = {}\n",
    "for idx, row in dem_types.iterrows():\n",
    "    dtype_dict[row['item']] = row['dtype']\n",
    "    \n",
    "lkup_fields = ['ppid',\n",
    " 'EpisodeNumber',\n",
    " 'AdmissionDate',\n",
    " 'ED_adate_dt',\n",
    " 'IndexAttDate',\n",
    " 'HOSP_adt',\n",
    " 'DischargeDate',\n",
    " 'HOSP_ddt',\n",
    " 'breq_dt',\n",
    " 'HOSP_FCC_dt',\n",
    " 'HOSP_FAS_dt',\n",
    " 'gt_m',\n",
    " 'gt_cc',\n",
    " 'gt_es_hosp',\n",
    " 'gt_dd',\n",
    " 'total_count_all',\n",
    " 'total_count_rehab',\n",
    " 'total_count_all_tf',\n",
    " 'total_n_disciplines',\n",
    " 'total_count_ooh_all',\n",
    " 'total_n_disciplines_gr',\n",
    " 'age_gr',\n",
    " 'total_count_cts_gr']\n",
    "\n",
    "base_path = ''\n",
    "model_path = ''\n",
    "train_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True)\n",
    "val_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True, dtype=dtype_dict)\n",
    "\n",
    "train_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in train_data.columns]\n",
    "train_data.columns = [col.replace(',', '_') if ',' in col else col for col in train_data.columns]\n",
    "val_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in val_data.columns]\n",
    "val_data.columns = [col.replace(',', '_') if ',' in col else col for col in val_data.columns]\n",
    "\n",
    "### Shuffle data when using time-series split\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "### Lookup fields\n",
    "train_lkup_m = train_data[lkup_fields]\n",
    "val_lkup_m = val_data[lkup_fields]\n",
    "### GT fields\n",
    "train_y = train_data['gt_cc']\n",
    "val_y = val_data['gt_cc']\n",
    "### XGBoost features\n",
    "train_x = train_data.loc[:, ~train_data.columns.isin(lkup_fields)]\n",
    "val_x = val_data.loc[:, ~val_data.columns.isin(lkup_fields)]\n",
    "all_x = pd.concat([train_x, val_x], axis=0)\n",
    "all_y = pd.concat([train_y, val_y], axis=0)\n",
    "print(train_x.columns.tolist())\n",
    "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5bc60-903c-4256-a821-33ef99130a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = 100\n",
    "rounds = 2000\n",
    "pos_weight = round(len(train_y_m[train_y_m==0]) / len(train_y_m[train_y_m==1]), 3)\n",
    "print('Weight scale parameter for imbalanced data:', pos_weight)\n",
    "print(round(len(train_y_m[train_y_m==1])/ len(train_y_m), 2))\n",
    "params_def = {\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 25,\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': .01,\n",
    "    #'colsample_bytree': .5,\n",
    "    #'alpha': 1\n",
    "    #'lambda': 2\n",
    "    ### For imbalanced data\n",
    "    #'scale_pos_weight': pos_weight\n",
    "    #'subsample': .6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ff2e0-87ff-4c05-9c24-9b48debb893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_kfold_performance(all_x, all_y, rounds, params_def, early_stopping, \n",
    "                         roc_title='Cross-validated ROC Curve over 10 folds (ICU/HDU admission).')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde0b6f8-484b-4302-87b9-75cc83ecc6ee",
   "metadata": {},
   "source": [
    "#### Validate on home discharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96edd770-3093-419c-b771-d9cd99e98352",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load features while specifying data types for memory efficiency\n",
    "dem_types = pd.read_csv('', names=['item', 'dtype'], skiprows=1)\n",
    "dtype_dict = {}\n",
    "for idx, row in dem_types.iterrows():\n",
    "    dtype_dict[row['item']] = row['dtype']\n",
    "    \n",
    "lkup_fields = ['ppid',\n",
    " 'EpisodeNumber',\n",
    " 'AdmissionDate',\n",
    " 'ED_adate_dt',\n",
    " 'IndexAttDate',\n",
    " 'HOSP_adt',\n",
    " 'DischargeDate',\n",
    " 'HOSP_ddt',\n",
    " 'breq_dt',\n",
    " 'HOSP_FCC_dt',\n",
    " 'HOSP_FAS_dt',\n",
    " 'gt_m',\n",
    " 'gt_cc',\n",
    " 'gt_es_hosp',\n",
    " 'gt_dd',\n",
    " 'total_count_all',\n",
    " 'total_count_rehab',\n",
    " 'total_count_all_tf',\n",
    " 'total_n_disciplines',\n",
    " 'total_count_ooh_all',\n",
    " 'total_n_disciplines_gr',\n",
    " 'age_gr',\n",
    " 'total_count_cts_gr']\n",
    "\n",
    "base_path = ''\n",
    "model_path = ''\n",
    "train_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True)\n",
    "val_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True, dtype=dtype_dict)\n",
    "\n",
    "train_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in train_data.columns]\n",
    "train_data.columns = [col.replace(',', '_') if ',' in col else col for col in train_data.columns]\n",
    "val_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in val_data.columns]\n",
    "val_data.columns = [col.replace(',', '_') if ',' in col else col for col in val_data.columns]\n",
    "\n",
    "### Shuffle data when using time-series split\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "### Lookup fields\n",
    "train_lkup_m = train_data[lkup_fields]\n",
    "val_lkup_m = val_data[lkup_fields]\n",
    "### GT fields\n",
    "train_y = train_data['gt_dd']\n",
    "val_y = val_data['gt_dd']\n",
    "### XGBoost features\n",
    "train_x = train_data.loc[:, ~train_data.columns.isin(lkup_fields)]\n",
    "val_x = val_data.loc[:, ~val_data.columns.isin(lkup_fields)]\n",
    "all_x = pd.concat([train_x, val_x], axis=0)\n",
    "all_y = pd.concat([train_y, val_y], axis=0)\n",
    "print(train_x.columns.tolist())\n",
    "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564bc04-260d-4e75-8b2a-8133a1bd514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = 100\n",
    "rounds = 2000\n",
    "pos_weight = round(len(train_y_m[train_y_m==0]) / len(train_y_m[train_y_m==1]), 3)\n",
    "print('Weight scale parameter for imbalanced data:', pos_weight)\n",
    "print(round(len(train_y_m[train_y_m==1])/ len(train_y_m), 2))\n",
    "params_def = {\n",
    "    'max_depth': 3,\n",
    "    'objective': 'binary:logistic',\n",
    "    'nthread': 25,\n",
    "    'eval_metric': 'logloss',\n",
    "    'eta': .01,\n",
    "    #'colsample_bytree': .5,\n",
    "    #'alpha': 1\n",
    "    #'lambda': 2\n",
    "    ### For imbalanced data\n",
    "    #'scale_pos_weight': pos_weight\n",
    "    #'subsample': .6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e465251c-6a94-400f-9f20-623d0b547cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_kfold_performance(all_x, all_y, rounds, params_def, early_stopping, \n",
    "                          roc_title='Cross-validated ROC Curve over 10 folds (home discharge).')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
