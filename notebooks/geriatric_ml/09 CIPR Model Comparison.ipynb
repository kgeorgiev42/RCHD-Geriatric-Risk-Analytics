{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17872b7b-01b2-4121-a536-cc0b807cb51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "from statistics import mean, median\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, auc, f1_score, RocCurveDisplay\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, ElasticNet\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.calibration import CalibrationDisplay, calibration_curve\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "import shap\n",
    "import xgboost as xgb\n",
    "from xgboost import cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feed4d4b-22f7-467d-9e62-b80a1cd47809",
   "metadata": {},
   "source": [
    "#### Compare diagnostic quality across various regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c95dc10-b5e3-43c3-9425-ab2e733db3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load features while specifying data types for memory efficiency   \n",
    "lkup_fields = ['ppid',\n",
    " 'EpisodeNumber',\n",
    " 'AdmissionDate',\n",
    " 'ED_adate_dt',\n",
    " 'IndexAttDate',\n",
    " 'HOSP_adt',\n",
    " 'DischargeDate',\n",
    " 'HOSP_ddt',\n",
    " 'breq_dt',\n",
    " 'HOSP_FCC_dt',\n",
    " 'HOSP_FAS_dt',\n",
    " 'gt_m',\n",
    " 'gt_cc',\n",
    " 'gt_es_hosp',\n",
    " 'gt_dd',\n",
    " 'total_count_all',\n",
    " 'total_count_rehab',\n",
    " 'total_count_all_tf',\n",
    " 'total_n_disciplines',\n",
    " 'total_count_ooh_all',\n",
    " 'total_n_disciplines_gr',\n",
    " 'age_gr',\n",
    " 'total_count_cts_gr']\n",
    "\n",
    "#### Load features while specifying data types for memory efficiency\n",
    "dem_types = pd.read_csv('', names=['item', 'dtype'], skiprows=1)\n",
    "dtype_dict = {}\n",
    "for idx, row in dem_types.iterrows():\n",
    "    dtype_dict[row['item']] = row['dtype']\n",
    "\n",
    "base_path = ''\n",
    "model_path = ''\n",
    "train_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True)\n",
    "val_data = pd.read_csv(os.path.join(base_path, ''), low_memory=True, dtype=dtype_dict)\n",
    "\n",
    "train_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in train_data.columns]\n",
    "train_data.columns = [col.replace(',', '_') if ',' in col else col for col in train_data.columns]\n",
    "val_data.columns = [col.replace('<', '_below_') if '<' in col else col for col in val_data.columns]\n",
    "val_data.columns = [col.replace(',', '_') if ',' in col else col for col in val_data.columns]\n",
    "\n",
    "### Shuffle data when using time-series split\n",
    "train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "val_data = val_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "### Lookup fields\n",
    "train_lkup_cts = train_data[lkup_fields]\n",
    "val_lkup_cts = val_data[lkup_fields]\n",
    "### GT fields\n",
    "train_y_cts = train_data['total_count_all_tf']\n",
    "val_y_cts = val_data['total_count_all_tf']\n",
    "### XGBoost features\n",
    "train_x_cts = train_data.drop(train_lkup_cts.columns.tolist(), axis=1)\n",
    "val_x_cts = val_data.drop(val_lkup_cts.columns.tolist(), axis=1)\n",
    "print('Training features')\n",
    "print(train_x_cts.columns.tolist())\n",
    "print(train_x_cts.shape, val_x_cts.shape, train_y_cts.shape, val_y_cts.shape)\n",
    "### Create XGBoost objects\n",
    "train_dm_cts = xgb.DMatrix(train_x_cts, label=train_y_cts)\n",
    "val_dm_cts = xgb.DMatrix(val_x_cts, label=val_y_cts)\n",
    "xgb_cts = xgb.Booster()\n",
    "xgb_cts.load_model('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f2222-0312-41e1-b7fc-659cb721044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Create model set\n",
    "\n",
    "regs = {\n",
    "    'OLS Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Elastic Net': ElasticNet(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'XGBoost': xgb_cts\n",
    "}\n",
    "\n",
    "ridge_params = {'fit_intercept': [True, False], 'copy_X': [True, False],\n",
    "                'solver': ['auto']}\n",
    "dtr_params = {'criterion': ['absolute_error', 'friedman_mse', 'poisson'], 'splitter': ['best', 'random'],\n",
    "              'min_samples_split': [2, 3, 5, 10], 'max_features': ['sqrt', 'log2']}\n",
    "rf_params = {'n_estimators': [5, 10, 15, 20],  'criterion': ['absolute_error', 'friedman_mse', 'poisson'], \n",
    "             'min_samples_split': [2, 3, 5, 10],\n",
    "             'max_features': ['sqrt', 'log2']}\n",
    "el_params = {'fit_intercept': [True, False], 'alpha': [0.001, 0.01, 0.1, 1.0], 'copy_X': [True, False],\n",
    "         'l1_ratio': [0.001, 0.1, 0.5, 1.0]}\n",
    "\n",
    "colors = ['#a6cee3', '#1f78b4', '#cab2d6', '#ff7f00', '#fb9a99', '#e31a1c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac91fa4a-064f-4e2c-b83d-9934b4342124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':12, 'font.weight':'normal', 'font.family':'serif'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a37941-361d-439f-9f80-018b16304deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_metric(labels_true, labels_pred, metric_func, n_iter=1000):\n",
    "    n = len(labels_true)\n",
    "    res = np.zeros(n_iter)\n",
    "    for i in range(n_iter):\n",
    "        ind = np.random.randint(0, n, n)\n",
    "        sample_true = labels_true[ind]\n",
    "        sample_pred = labels_pred[ind]\n",
    "        res[i] = metric_func(sample_true, sample_pred)\n",
    "    return res\n",
    "\n",
    "def compute_ci(bootstrap_res, ci=0.95):\n",
    "    lp = (1 - ci) / 2\n",
    "    up = 1 - lp\n",
    "    return np.round(np.percentile(bootstrap_res, [lp*100, up*100]), 3)\n",
    "\n",
    "def rmse(labels_true, labels_pred):\n",
    "    return np.sqrt(mean_squared_error(labels_true, labels_pred))\n",
    "\n",
    "def mae(labels_true, labels_pred):\n",
    "    return mean_absolute_error(labels_true, labels_pred)\n",
    "\n",
    "def mape(labels_true, labels_pred):\n",
    "    return np.mean(2 * np.abs(labels_true - labels_pred) / (np.abs(labels_true) + np.abs(labels_pred))) * 100\n",
    "\n",
    "def mape_c(labels_true, labels_pred):\n",
    "    mask = labels_true != 0\n",
    "    return np.mean(np.abs((labels_true[mask] - labels_pred[mask]) / labels_true[mask])) * 100\n",
    "\n",
    "def f1_cs(labels_true, labels_pred):\n",
    "    return f1_score(labels_true, labels_pred, average='macro')\n",
    "\n",
    "def kappa_cs(labels_true, labels_pred):\n",
    "    return cohen_kappa_score(labels_true, labels_pred, weights='quadratic')\n",
    "\n",
    "def evaluate_model(labels_val, labels_pred_val, evals_result=None, \n",
    "                  task='Total health contacts', tgt='Total health contacts', tp='ED attendance'):\n",
    "    print('Evaluating model for target: ' + task)\n",
    "    res_dict = {}\n",
    "    res_dict['timepoint'] = tp\n",
    "    res_dict['target'] = tgt\n",
    "    #plot_learning_curve(model, evals_result)\n",
    "    #### Get performance measures with 95% CI\n",
    "    rmse_ci = compute_ci(bootstrap_metric(labels_val, labels_pred_val, rmse))\n",
    "    mae_ci = compute_ci(bootstrap_metric(labels_val, labels_pred_val, mae))\n",
    "    mape_ci = compute_ci(bootstrap_metric(labels_val, labels_pred_val, mape_c))\n",
    "    rmse_val = round(rmse(labels_val, labels_pred_val), 3)\n",
    "    mae_val = round(mae(labels_val, labels_pred_val), 3)\n",
    "    mape_val = round(mape_c(labels_val, labels_pred_val), 3)\n",
    "    print(f'RMSE: {rmse_val}, 95% CI: {rmse_ci}')\n",
    "    print(f'MAE: {mae_val}, 95% CI: {mae_ci}')\n",
    "    print(f'MAPE: {mape_val}, 95% CI: {mape_ci}')\n",
    "    res_dict['RMSE'] = rmse_val\n",
    "    res_dict['RMSE-upper'] = rmse_ci[0]\n",
    "    res_dict['RMSE-lower'] = rmse_ci[1]\n",
    "    res_dict['MAE'] = mae_val\n",
    "    res_dict['MAE-upper'] = mae_ci[0]\n",
    "    res_dict['MAE-lower'] = mae_ci[1]\n",
    "    res_dict['MAPE'] = mape_val\n",
    "    res_dict['MAPE-upper'] = mape_ci[0]\n",
    "    res_dict['MAPE-lower'] = mape_ci[1]\n",
    "    print('Evaluation complete.')\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931ba9c0-35f5-4de4-9336-807aa08d8995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_regs(train_x, train_y, val_x, val_y, regs):\n",
    "    res_df = pd.DataFrame()\n",
    "    params = {}\n",
    "    for reg_name, reg in regs.items():\n",
    "        print(f'Evaluating {reg_name}')\n",
    "        if reg_name == 'XGBoost':\n",
    "            print(f'Evaluating {reg_name}...')\n",
    "            preds = reg.predict(xgb.DMatrix(val_x))\n",
    "        else:\n",
    "            print(f'Fitting {reg_name}...')\n",
    "            if reg_name == 'Ridge Regression':\n",
    "                params = ridge_params\n",
    "            elif reg_name == 'Decision Tree':\n",
    "                params = dtr_params\n",
    "            elif reg_name == 'Elastic Net':\n",
    "                params = el_params\n",
    "            elif reg_name == 'Random Forest':\n",
    "                params = rf_params\n",
    "                \n",
    "            gcv = GridSearchCV(reg, params, verbose=1, scoring='neg_mean_absolute_error')\n",
    "            gcv.fit(train_x, train_y)\n",
    "            bm = gcv.best_estimator_\n",
    "            preds = bm.predict(val_x)\n",
    "\n",
    "        res_dict = pd.DataFrame.from_dict(evaluate_model(val_y, preds), orient='index').T\n",
    "        res_dict['Model'] = reg_name\n",
    "        res_df = pd.concat([res_df, res_dict], axis=0)\n",
    "        print(res_df)\n",
    "    print('Evaluation complete')\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b90fa2-c77f-43de-8d8f-5a93f3fa31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = eval_regs(train_x_cts, train_y_cts, val_x_cts, val_y_cts, regs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07220baf-e492-4f44-bbc9-ae255f6b7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
